{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import keras\n",
    "import keras.preprocessing.image\n",
    "from keras_retinanet.models.resnet import custom_objects\n",
    "from keras_retinanet.preprocessing.videotag import VIDEOtagGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import skimage.io\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_session():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.Session(config=config)\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "keras.backend.tensorflow_backend.set_session(get_session())\n",
    "\n",
    "\n",
    "args_input_json = '../dataset/videotag/0101_0102/annotations/instances.json'\n",
    "args_image_dir = '../dataset/videotag/0101_0102/images'\n",
    "ROOT_DIR = os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/models.py:274: UserWarning: Output \"non_maximum_suppression_3\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"non_maximum_suppression_3\" during training.\n",
      "  sample_weight_mode=sample_weight_mode)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('/Users/luke/Documents/ml_models/resnet50_coco_best_v1.2.2.h5', custom_objects=custom_objects)\n",
    "# mymodel = keras.models.load_model('/Users/luke/Documents/ml_models/resnet50_coco_01.h5', custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_CATEGORY_MAP = \"../assets/json/category.json\"\n",
    "\n",
    "coco_class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "                'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "                'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "                'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "                'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "                'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "                'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "                'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "                'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "                'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "                'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "                'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "                'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "                'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "                'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "\n",
    "###################################################################\n",
    "# Load VIDEOtag, COCO category 맵핑 데이타\n",
    "# COCO Model에서 검출된 class와 VIDEOtag에 미리 정해져 있는 class매칭을 위해 사용\n",
    "###################################################################\n",
    "map_data = open(FILE_CATEGORY_MAP).read()\n",
    "tmp_vt_coco_cate_map = json.loads(map_data)[\"categories\"]\n",
    "\n",
    "# NOTE : 빠른 검색을 위해 dictionary로 생성\n",
    "vt_coco_cate_map = {}\n",
    "for cate_data in tmp_vt_coco_cate_map:\n",
    "    vt_coco_cate_map[cate_data['id']] = cate_data\n",
    "\n",
    "\n",
    "json_data = open(args_input_json).read()\n",
    "data = json.loads(json_data)\n",
    "\n",
    "# NOTE : VIDEOtag Data (원본)\n",
    "vt_anno_ary = data['annotations']\n",
    "vt_img_ary = data['images']\n",
    "vt_cate_ary = data['categories']\n",
    "\n",
    "# NOTE : VIDEOtag Data (검색용)\n",
    "vt_anno_ids_of_imageids = {}\n",
    "vt_anno_dic = {}\n",
    "vt_cate_ary_dic = {}\n",
    "\n",
    "for anno in vt_anno_ary:\n",
    "    vt_anno_dic[anno['id']] = anno\n",
    "\n",
    "for cate in vt_cate_ary:\n",
    "    vt_cate_ary_dic[cate['id']] = cate\n",
    "\n",
    "for image in vt_img_ary:\n",
    "    anno_ids = []\n",
    "    image_id = image['id']\n",
    "\n",
    "    for anno in vt_anno_ary:\n",
    "        anno_img_id = anno['image_id']\n",
    "        anno_id = anno['id']\n",
    "        if anno_img_id == image_id:\n",
    "            anno_ids.append(anno_id)\n",
    "\n",
    "    vt_anno_ids_of_imageids[image_id] = anno_ids\n",
    "\n",
    "def getAnnosByImgId(img_id):\n",
    "    anno_ids = vt_anno_ids_of_imageids[img_id]\n",
    "    result = []\n",
    "    for anno_id in anno_ids:  \n",
    "        result.append(vt_anno_dic[anno_id])\n",
    "\n",
    "    return result\n",
    "\n",
    "def insertBboxToAnno(anno_id, bbox):\n",
    "    for anno in vt_anno_ary:\n",
    "        if anno['id'] == anno_id:\n",
    "            anno['bbox'] = bbox\n",
    "            return anno\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1081\n",
      "1/1081\n",
      "2/1081\n",
      "3/1081\n",
      "4/1081\n",
      "5/1081\n",
      "6/1081\n",
      "7/1081\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "insertBboxToAnno() missing 1 required positional argument: 'segmentation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-a62a30741714>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ma_coco_cate_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma_coco_cate_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0ma_coco_cate_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0md_coco_cate_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                     \u001b[0minsertBboxToAnno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_vt_anno_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_bbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                     \u001b[0mconfirm_vt_anno_points\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpoint_y\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint_x\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint_y\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint_x\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: insertBboxToAnno() missing 1 required positional argument: 'segmentation'"
     ]
    }
   ],
   "source": [
    "###################################################################\n",
    "# 모든 이미지에 대하여 predict를 실시한다.\n",
    "###################################################################\n",
    "img_total = len(vt_img_ary)\n",
    "for img_idx, img_data in enumerate(vt_img_ary): \n",
    "    # NOTE : d_ -> detected_, a_ -> answer_\n",
    "    \n",
    "    if img_idx > 10:\n",
    "        break\n",
    "\n",
    "    print(str(img_idx)+'/'+str(img_total))\n",
    "    img_id = img_data['id']\n",
    "\n",
    "    ###################################################################\n",
    "    # videotag image에 등록되어 있느 annotation이 있는지 확인 후, 로드\n",
    "    ###################################################################\n",
    "    a_vt_annos = getAnnosByImgId(img_id)\n",
    "\n",
    "    if len(a_vt_annos) == 0:\n",
    "        continue\n",
    "\n",
    "    ###################################################################\n",
    "    # videotag image이 로드\n",
    "    ###################################################################\n",
    "    img_path = os.path.join(ROOT_DIR, args_image_dir, img_data['file_name']) \n",
    "    image = skimage.io.imread(img_path)\n",
    "    img_height, img_width = image.shape[:2]\n",
    "    # If grayscale. Convert to RGB for consistency.\n",
    "    if image.ndim != 3:\n",
    "        image = skimage.color.gray2rgb(image)\n",
    "\n",
    "    ###################################################################\n",
    "    # Run detection\n",
    "    ###################################################################\n",
    "#     d_results = model.detect([image], verbose=0)\n",
    "    _, _, detections = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "    \n",
    "#     predicted_labels = np.argmax(detections[0, :, 4:], axis=1)\n",
    "#     scores = detections[0, np.arange(detections.shape[1]), 4 + predicted_labels]\n",
    "\n",
    "    # correct for image scale\n",
    "#     detections[0, :, :4] /= scale\n",
    "\n",
    "\n",
    "#     print(predicted_labels, scores)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     draw = image.copy()\n",
    "# #     draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "#     # visualize detections\n",
    "#     for idx, (label, score) in enumerate(zip(predicted_labels, scores)):\n",
    "#         if score < 0.5:\n",
    "#             continue\n",
    "#         b = detections[0, idx, :4].astype(int)\n",
    "#         cv2.rectangle(draw, (b[0], b[1]), (b[2], b[3]), (0, 0, 255), 3)\n",
    "#         caption = \"{} {:.3f}\".format(coco_class_names[label+1], score)\n",
    "#         cv2.putText(draw, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 0), 3)\n",
    "#         cv2.putText(draw, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 255), 2)\n",
    "\n",
    "#     # visualize annotations\n",
    "#     # for annotation in annotations:\n",
    "#     #     label = int(annotation[4])\n",
    "#     #     b = annotation[:4].astype(int)\n",
    "#     #     cv2.rectangle(draw, (b[0], b[1]), (b[2], b[3]), (0, 255, 0), 2)\n",
    "#     #     caption = \"{}\".format(val_generator.label_to_name(label))\n",
    "#     #     cv2.putText(draw, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 0), 3)\n",
    "#     #     cv2.putText(draw, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
    "\n",
    "#     plt.figure(figsize=(15, 15))\n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(draw)\n",
    "#     plt.show()\n",
    "    \n",
    "#     break;\n",
    "\n",
    "    # Result\n",
    "#     d_r = d_results[0]\n",
    "\n",
    "#     d_rois = detections[0, idx, :4].astype(int)#d_r['rois'] # y1, x1, y2, x2\n",
    "    d_scores = detections[0, np.arange(detections.shape[1]), 4 + predicted_labels]#d_r['scores']\n",
    "    d_coco_cate_ids = np.argmax(detections[0, :, 4:], axis=1)#d_r['class_ids']\n",
    "\n",
    "\n",
    "    # 확인용\n",
    "    confirm_matching_classes = []\n",
    "    confirm_vt_anno_points = []\n",
    "\n",
    "    is_found = 0\n",
    "\n",
    "    ###################################################################\n",
    "    # 추출된 data를 VIDEOtag Annotation과 비교\n",
    "    ###################################################################\n",
    "    for d_idx, score in enumerate(d_scores):\n",
    "        '''\n",
    "        스코어 낮은 것은 의미가 없는 것으로 판단함\n",
    "        아래에 VIDEOtag과 COCO의 데이타를 비교하는 로직이 있으므로 Predict의 정확도는\n",
    "        현재 로직에서 의미가 없음\n",
    "\n",
    "        if score < 0.9: \n",
    "            continue\n",
    "        '''\n",
    "\n",
    "        d_coco_cate_id = d_coco_cate_ids[d_idx]\n",
    "        d_coco_cate_name = coco_class_names[d_coco_cate_id]\n",
    "        y1, x1, y2, x2 = detections[0, d_idx, :4].astype(int)\n",
    "        d_bbox = [int(x1), int(y1), int(x2 - x1), int(y2 - y1)]\n",
    "        \n",
    "        ###################################################################\n",
    "        # coco model에서 검출된 annotation들이 videotag annotation(정답)들과 비교하여\n",
    "        # 일치할 경우가 있을 때, 해당 videotag annotation에 bbox정보를 추가한다.\n",
    "        ###################################################################\n",
    "        for a_vt_anno in a_vt_annos:\n",
    "            a_vt_anno_id = a_vt_anno['id']\n",
    "            a_vt_cate_id = a_vt_anno['category_id']\n",
    "            a_vt_cate_name = vt_cate_ary_dic[a_vt_cate_id]['name']\n",
    "\n",
    "            point_x = int(img_width * a_vt_anno['x_pos'])\n",
    "            point_y = int(img_height * a_vt_anno['y_pos'])\n",
    "\n",
    "            # NOTE : 기대하는 VIDEOtag의 coco categories 확인. 현재(2018.02) 매칭되는 category가 많지 않다.\n",
    "            a_coco_cate_ids = vt_coco_cate_map[a_vt_cate_id]['coco_ids']\n",
    "            if len(a_coco_cate_ids) == 0:\n",
    "                continue\n",
    "\n",
    "            # NOTE: 포인트가 마스크 영역에 속하는 확인\n",
    "            if not point_x >= x1 and point_x <= x2 and point_y >= y1 and point_y <= y2:\n",
    "                continue\n",
    "\n",
    "            for a_coco_cate_id in a_coco_cate_ids:\n",
    "                if a_coco_cate_id == d_coco_cate_id:\n",
    "                    insertBboxToAnno(a_vt_anno_id, d_bbox)\n",
    "\n",
    "                    confirm_vt_anno_points.append([point_y-5, point_x-5, point_y+5, point_x+5])\n",
    "                    confirm_matching_classes.append([d_coco_cate_name, a_vt_cate_name])\n",
    "                    is_found = 1\n",
    "                    break\n",
    "\n",
    "    if len(confirm_matching_classes) > 0:\n",
    "        print('매칭된 카테고리 확인 - ', confirm_matching_classes)\n",
    "        print('----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
