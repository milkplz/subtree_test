{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(\"..\")\n",
    "\n",
    "import keras\n",
    "import keras.preprocessing.image\n",
    "from keras_retinanet.models.resnet import custom_objects\n",
    "from keras_retinanet.preprocessing.videotag import VIDEOtagGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import skimage.io\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_session():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.Session(config=config)\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "keras.backend.tensorflow_backend.set_session(get_session())\n",
    "\n",
    "\n",
    "args_input_json = '../dataset/videotag/0101_0102/instances.json'\n",
    "args_image_dir = '../dataset/videotag/0101_0102/images'\n",
    "args_output_json = '../dataset/videotag/0101_0102/result/instances.json'\n",
    "ROOT_DIR = os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/models.py:274: UserWarning: Output \"non_maximum_suppression_2\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"non_maximum_suppression_2\" during training.\n",
      "  sample_weight_mode=sample_weight_mode)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('/Users/luke/Documents/ml_models/resnet50_coco_best_v1.2.2.h5', custom_objects=custom_objects)\n",
    "# mymodel = keras.models.load_model('/Users/luke/Documents/ml_models/resnet50_coco_01.h5', custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_CATEGORY_MAP = \"../assets/json/category.json\"\n",
    "\n",
    "coco_class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "                'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "                'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "                'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "                'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "                'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "                'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "                'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "                'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "                'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "                'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "                'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "                'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "                'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "                'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "\n",
    "###################################################################\n",
    "# Load VIDEOtag, COCO category 맵핑 데이타\n",
    "# COCO Model에서 검출된 class와 VIDEOtag에 미리 정해져 있는 class매칭을 위해 사용\n",
    "###################################################################\n",
    "map_data = open(FILE_CATEGORY_MAP).read()\n",
    "tmp_vt_coco_cate_map = json.loads(map_data)[\"categories\"]\n",
    "\n",
    "# NOTE : 빠른 검색을 위해 dictionary로 생성\n",
    "vt_coco_cate_map = {}\n",
    "for cate_data in tmp_vt_coco_cate_map:\n",
    "    vt_coco_cate_map[cate_data['id']] = cate_data\n",
    "\n",
    "\n",
    "json_data = open(args_input_json).read()\n",
    "data = json.loads(json_data)\n",
    "\n",
    "# NOTE : VIDEOtag Data (원본)\n",
    "vt_anno_ary = data['annotations']\n",
    "vt_img_ary = data['images']\n",
    "vt_cate_ary = data['categories']\n",
    "\n",
    "# NOTE : VIDEOtag Data (검색용)\n",
    "vt_anno_ids_of_imageids = {}\n",
    "vt_anno_dic = {}\n",
    "vt_cate_ary_dic = {}\n",
    "\n",
    "for anno in vt_anno_ary:\n",
    "    vt_anno_dic[anno['id']] = anno\n",
    "\n",
    "for cate in vt_cate_ary:\n",
    "    vt_cate_ary_dic[cate['id']] = cate\n",
    "\n",
    "for image in vt_img_ary:\n",
    "    anno_ids = []\n",
    "    image_id = image['id']\n",
    "\n",
    "    for anno in vt_anno_ary:\n",
    "        anno_img_id = anno['image_id']\n",
    "        anno_id = anno['id']\n",
    "        if anno_img_id == image_id:\n",
    "            anno_ids.append(anno_id)\n",
    "\n",
    "    vt_anno_ids_of_imageids[image_id] = anno_ids\n",
    "\n",
    "def getAnnosByImgId(img_id):\n",
    "    anno_ids = vt_anno_ids_of_imageids[img_id]\n",
    "    result = []\n",
    "    for anno_id in anno_ids:  \n",
    "        result.append(vt_anno_dic[anno_id])\n",
    "\n",
    "    return result\n",
    "\n",
    "def insertBboxToAnno(anno_id, bbox):\n",
    "    for anno in vt_anno_ary:\n",
    "        if anno['id'] == anno_id:\n",
    "            anno['bbox'] = bbox\n",
    "            return anno\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/1081\n",
      "43/1081\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value batch_normalization_67/gamma\n\t [[Node: batch_normalization_67/gamma/read = Identity[T=DT_FLOAT, _class=[\"loc:@batch_normalization_67/gamma\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](batch_normalization_67/gamma)]]\n\nCaused by op 'batch_normalization_67/gamma/read', defined at:\n  File \"/Users/luke/.pyenv/versions/3.6.3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/luke/.pyenv/versions/3.6.3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-26ea1c2c7b9b>\", line 1, in <module>\n    model = keras.models.load_model('/Users/luke/Documents/ml_models/resnet50_coco_best_v1.2.2.h5', custom_objects=custom_objects)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/models.py\", line 243, in load_model\n    model = model_from_config(model_config, custom_objects=custom_objects)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/models.py\", line 317, in model_from_config\n    return layer_module.deserialize(config, custom_objects=custom_objects)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/layers/__init__.py\", line 55, in deserialize\n    printable_module_name='layer')\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/utils/generic_utils.py\", line 144, in deserialize_keras_object\n    list(custom_objects.items())))\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/engine/topology.py\", line 2520, in from_config\n    process_node(layer, node_data)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/engine/topology.py\", line 2477, in process_node\n    layer(input_tensors[0], **kwargs)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/engine/topology.py\", line 590, in __call__\n    self.build(input_shapes[0])\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/layers/normalization.py\", line 107, in build\n    constraint=self.gamma_constraint)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/engine/topology.py\", line 414, in add_weight\n    constraint=constraint)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 392, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 213, in __init__\n    constraint=constraint)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 356, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 125, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2071, in identity\n    \"Identity\", input=input, name=name)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value batch_normalization_67/gamma\n\t [[Node: batch_normalization_67/gamma/read = Identity[T=DT_FLOAT, _class=[\"loc:@batch_normalization_67/gamma\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](batch_normalization_67/gamma)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value batch_normalization_67/gamma\n\t [[Node: batch_normalization_67/gamma/read = Identity[T=DT_FLOAT, _class=[\"loc:@batch_normalization_67/gamma\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](batch_normalization_67/gamma)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-609280ae8f6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m###################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#     d_results = model.detect([image], verbose=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m#     predicted_labels = np.argmax(detections[0, :, 4:], axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1950\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1952\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1953\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value batch_normalization_67/gamma\n\t [[Node: batch_normalization_67/gamma/read = Identity[T=DT_FLOAT, _class=[\"loc:@batch_normalization_67/gamma\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](batch_normalization_67/gamma)]]\n\nCaused by op 'batch_normalization_67/gamma/read', defined at:\n  File \"/Users/luke/.pyenv/versions/3.6.3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/luke/.pyenv/versions/3.6.3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-26ea1c2c7b9b>\", line 1, in <module>\n    model = keras.models.load_model('/Users/luke/Documents/ml_models/resnet50_coco_best_v1.2.2.h5', custom_objects=custom_objects)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/models.py\", line 243, in load_model\n    model = model_from_config(model_config, custom_objects=custom_objects)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/models.py\", line 317, in model_from_config\n    return layer_module.deserialize(config, custom_objects=custom_objects)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/layers/__init__.py\", line 55, in deserialize\n    printable_module_name='layer')\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/utils/generic_utils.py\", line 144, in deserialize_keras_object\n    list(custom_objects.items())))\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/engine/topology.py\", line 2520, in from_config\n    process_node(layer, node_data)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/engine/topology.py\", line 2477, in process_node\n    layer(input_tensors[0], **kwargs)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/engine/topology.py\", line 590, in __call__\n    self.build(input_shapes[0])\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/layers/normalization.py\", line 107, in build\n    constraint=self.gamma_constraint)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/engine/topology.py\", line 414, in add_weight\n    constraint=constraint)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 392, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 213, in __init__\n    constraint=constraint)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 356, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 125, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2071, in identity\n    \"Identity\", input=input, name=name)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/Users/luke/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value batch_normalization_67/gamma\n\t [[Node: batch_normalization_67/gamma/read = Identity[T=DT_FLOAT, _class=[\"loc:@batch_normalization_67/gamma\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](batch_normalization_67/gamma)]]\n"
     ]
    }
   ],
   "source": [
    "###################################################################\n",
    "# 모든 이미지에 대하여 predict를 실시한다.\n",
    "###################################################################\n",
    "img_total = len(vt_img_ary)\n",
    "\n",
    "for img_idx, img_data in enumerate(vt_img_ary): \n",
    "    # NOTE : d_ -> detected_, a_ -> answer_\n",
    "    \n",
    "    if img_idx < 42:\n",
    "        continue\n",
    "        \n",
    "    if img_idx > 100:\n",
    "        break\n",
    "\n",
    "    print(str(img_idx)+'/'+str(img_total))\n",
    "    img_id = img_data['id']\n",
    "\n",
    "    ###################################################################\n",
    "    # videotag image에 등록되어 있느 annotation이 있는지 확인 후, 로드\n",
    "    ###################################################################\n",
    "    a_vt_annos = getAnnosByImgId(img_id)\n",
    "\n",
    "    if len(a_vt_annos) == 0:\n",
    "        continue\n",
    "\n",
    "    ###################################################################\n",
    "    # videotag image이 로드\n",
    "    ###################################################################\n",
    "    img_path = os.path.join(ROOT_DIR, args_image_dir, img_data['file_name']) \n",
    "    image = skimage.io.imread(img_path)\n",
    "    img_height, img_width = image.shape[:2]\n",
    "    \n",
    "    # If grayscale. Convert to RGB for consistency.\n",
    "    if image.ndim != 3:\n",
    "        image = skimage.color.gray2rgb(image)\n",
    "\n",
    "    ###################################################################\n",
    "    # Run detection\n",
    "    ###################################################################\n",
    "#     d_results = model.detect([image], verbose=0)\n",
    "    _, _, detections = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "    \n",
    "#     predicted_labels = np.argmax(detections[0, :, 4:], axis=1)\n",
    "#     scores = detections[0, np.arange(detections.shape[1]), 4 + predicted_labels]\n",
    "\n",
    "    # correct for image scale\n",
    "#     detections[0, :, :4] /= scale\n",
    "\n",
    "\n",
    "#     print(predicted_labels, scores)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     draw = image.copy()\n",
    "# #     draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "#     # visualize detections\n",
    "#     for idx, (label, score) in enumerate(zip(predicted_labels, scores)):\n",
    "#         if score < 0.5:\n",
    "#             continue\n",
    "#         b = detections[0, idx, :4].astype(int)\n",
    "#         cv2.rectangle(draw, (b[0], b[1]), (b[2], b[3]), (0, 0, 255), 3)\n",
    "#         caption = \"{} {:.3f}\".format(coco_class_names[label+1], score)\n",
    "#         cv2.putText(draw, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 0), 3)\n",
    "#         cv2.putText(draw, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 255), 2)\n",
    "\n",
    "#     # visualize annotations\n",
    "#     # for annotation in annotations:\n",
    "#     #     label = int(annotation[4])\n",
    "#     #     b = annotation[:4].astype(int)\n",
    "#     #     cv2.rectangle(draw, (b[0], b[1]), (b[2], b[3]), (0, 255, 0), 2)\n",
    "#     #     caption = \"{}\".format(val_generator.label_to_name(label))\n",
    "#     #     cv2.putText(draw, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 0), 3)\n",
    "#     #     cv2.putText(draw, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
    "\n",
    "#     plt.figure(figsize=(15, 15))\n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(draw)\n",
    "#     plt.show()\n",
    "    \n",
    "#     break\n",
    "\n",
    "    # Result\n",
    "#     d_r = d_results[0]\n",
    "\n",
    "#     d_rois = detections[0, idx, :4].astype(int)#d_r['rois'] # y1, x1, y2, x2\n",
    "    d_coco_cate_ids = np.argmax(detections[0, :, 4:], axis=1)#d_r['class_ids']\n",
    "    d_scores = detections[0, np.arange(detections.shape[1]), 4 + d_coco_cate_ids]#d_r['scores']\n",
    "\n",
    "\n",
    "    # 확인용\n",
    "    confirm_matching_classes = []\n",
    "    confirm_vt_anno_points = []\n",
    "\n",
    "    is_found = 0\n",
    "    \n",
    "    draw = image.copy()\n",
    "\n",
    "    ###################################################################\n",
    "    # 추출된 data를 VIDEOtag Annotation과 비교\n",
    "    ###################################################################\n",
    "    for d_idx, score in enumerate(d_scores):\n",
    "        '''\n",
    "        스코어 낮은 것은 의미가 없는 것으로 판단함\n",
    "        아래에 VIDEOtag과 COCO의 데이타를 비교하는 로직이 있으므로 Predict의 정확도는\n",
    "        현재 로직에서 의미가 없음\n",
    "        '''\n",
    "        \n",
    "        if score < 0.7:\n",
    "            continue\n",
    "\n",
    "        d_coco_cate_id = d_coco_cate_ids[d_idx]+1\n",
    "        d_coco_cate_name = coco_class_names[d_coco_cate_id]\n",
    "        y1, x1, y2, x2 = detections[0, d_idx, :4].astype(int)\n",
    "        d_bbox = [int(x1), int(y1), int(x2 - x1), int(y2 - y1)]\n",
    "        \n",
    "#         b = detections[0, d_idx, :4].astype(int)\n",
    "#         cv2.rectangle(draw, (y1, x1), (y2, x2), (0, 0, 255), 3)\n",
    "#         caption = \"{} {:.3f}\".format(d_coco_cate_name, score)\n",
    "#         cv2.putText(draw, caption, (y1, x1 - 10), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 0), 3)\n",
    "#         cv2.putText(draw, caption, (y1, x1 - 10), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 255), 2)\n",
    "        \n",
    "        \n",
    "        ###################################################################\n",
    "        # coco model에서 검출된 annotation들이 videotag annotation(정답)들과 비교하여\n",
    "        # 일치할 경우가 있을 때, 해당 videotag annotation에 bbox정보를 추가한다.\n",
    "        ###################################################################\n",
    "        for a_vt_anno in a_vt_annos:\n",
    "            a_vt_anno_id = a_vt_anno['id']\n",
    "            a_vt_cate_id = a_vt_anno['category_id']\n",
    "            a_vt_cate_name = vt_cate_ary_dic[a_vt_cate_id]['name']\n",
    "\n",
    "            point_x = int(img_width * a_vt_anno['x_pos'])\n",
    "            point_y = int(img_height * a_vt_anno['y_pos'])\n",
    "\n",
    "            # NOTE : 기대하는 VIDEOtag의 coco categories 확인. 현재(2018.02) 매칭되는 category가 많지 않다.\n",
    "            a_coco_cate_ids = vt_coco_cate_map[a_vt_cate_id]['coco_ids']\n",
    "            if len(a_coco_cate_ids) == 0:\n",
    "                continue\n",
    "\n",
    "            # NOTE: 포인트가 마스크 영역에 속하는 확인\n",
    "            if point_x < x1 and point_x > x2 and point_y < y1 and point_y > y2:\n",
    "                continue\n",
    "\n",
    "            for a_coco_cate_id in a_coco_cate_ids:\n",
    "                if a_coco_cate_id == d_coco_cate_id:\n",
    "                    insertBboxToAnno(a_vt_anno_id, d_bbox)\n",
    "                    \n",
    "                    cv2.rectangle(draw, (y1, x1), (y2, x2), (0, 0, 255), 3)\n",
    "                    cx = int(x1 + (x2-x1)*0.5)\n",
    "                    cy = int(y1 + (y2-y1)*0.5)\n",
    "                    cv2.rectangle(draw, (cy-5, cx-5), (cy+5, cx+5), (0, 0, 255), 3)\n",
    "                    caption = \"{} {:.3f}\".format(d_coco_cate_name, score)\n",
    "                    cv2.putText(draw, caption, (y1, x1 - 10), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 255), 2)\n",
    "#                     print(d_bbox)\n",
    "#                     print(img_width, img_height)\n",
    "\n",
    "                    confirm_vt_anno_points.append([point_y-5, point_x-5, point_y+5, point_x+5])\n",
    "                    confirm_matching_classes.append([d_coco_cate_name, a_vt_cate_name])\n",
    "                    is_found = 1\n",
    "                    break\n",
    "                \n",
    "    if len(confirm_vt_anno_points) > 0:\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        plt.axis('off')\n",
    "        plt.imshow(draw)\n",
    "        plt.show()\n",
    "\n",
    "    if len(confirm_matching_classes) > 0:\n",
    "        print('매칭된 카테고리 확인 - ', confirm_matching_classes)\n",
    "        print('----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../dataset/videotag/0101_0102/result/instances.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-77544cdf8f14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresult_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvt_img_ary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../dataset/videotag/0101_0102/result/instances.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../dataset/videotag/0101_0102/result/instances.json'"
     ]
    }
   ],
   "source": [
    "result_json = {}\n",
    "result_json['annotations'] = vt_anno_ary\n",
    "result_json['images'] = vt_img_ary\n",
    "\n",
    "with open('../dataset/videotag/0101_0102/result/instances.json', 'w') as outfile:\n",
    "    json.dump(result_json, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
