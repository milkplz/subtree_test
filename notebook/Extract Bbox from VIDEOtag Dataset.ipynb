{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import keras\n",
    "import keras.preprocessing.image\n",
    "from keras_retinanet.models.resnet import custom_objects\n",
    "from keras_retinanet.preprocessing.videotag import VIDEOtagGenerator\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import skimage.io\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_session():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.Session(config=config)\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "keras.backend.tensorflow_backend.set_session(get_session())\n",
    "\n",
    "\n",
    "args_input_json = '/Users/luke/Documents/ml_datasets/new/videotag/0101_0102/instances.json'\n",
    "args_image_dir = '/Users/luke/Documents/ml_datasets/new/videotag/0101_0102/images'\n",
    "args_image_log_dir = '/Users/luke/Documents/ml_datasets/new/videotag/0101_0102/logs'\n",
    "args_output_json = '/Users/luke/Documents/ml_datasets/new/videotag/0101_0102/result/instances.json'\n",
    "ROOT_DIR = os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luke/.pyenv/versions/3.6.2/envs/py362/lib/python3.6/site-packages/keras/models.py:274: UserWarning: Output \"nms\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"nms\" during training.\n",
      "  sample_weight_mode=sample_weight_mode)\n"
     ]
    }
   ],
   "source": [
    "# model = keras.models.load_model('/Users/luke/Documents/ml_models/resnet50_coco_best_v1.2.2.h5', custom_objects=custom_objects)\n",
    "# model = keras.models.load_model('/Users/luke/Documents/ml_models/deep/cate50/resnet50_csv_epoch_50_loss_0.90363.h5', custom_objects=custom_objects)\n",
    "model = keras.models.load_model('/Users/luke/Documents/ml_models/deep/cate3/resnet50_csv_epoch_20_loss_0.88256.h5', custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load COCO Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "                'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "                'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "                'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "                'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "                'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "                'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "                'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "                'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "                'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "                'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "                'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "                'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "                'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "                'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "\n",
    "FILE_CATEGORY_MAP = \"../assets/json/category.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DeepFashion Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_class_names = ['Anorak','Blazer','Blouse','Bomber','Button-Down','Cardigan',\n",
    "                    'Flannel','Halter','Henley','Hoodie',\n",
    "                    'Jacket','Jersey','Parka','Peacoat','Poncho','Sweater','Tank',\n",
    "                    'Tee','Top','Turtleneck','Capris','Chinos','Culottes','Cutoffs','Gauchos',\n",
    "                    'Jeans','Jeggings','Jodhpurs','Joggers','Leggings','Sarong','Shorts',\n",
    "                    'Skirt','Sweatpants','Sweatshorts','Trunks','Caftan','Cape','Coat',\n",
    "                    'Coverup','Dress','Jumpsuit','Kaftan','Kimono','Nightdress','Onesie',\n",
    "                    'Robe','Romper','Shirtdress','Sundress']\n",
    "\n",
    "FILE_CATEGORY_MAP = \"../assets/json/category_map_deep.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_class_names = ['upper-body', 'lower-body', 'full-body']\n",
    "\n",
    "FILE_CATEGORY_MAP = \"../assets/json/category_map_deep.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load COCO+Deepfashion Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "                'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "                'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "                'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "                'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "                'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "                'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "                'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "                'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "                'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "                'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "                'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "                'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "                'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "                'teddy bear', 'hair drier', 'toothbrush',\n",
    "            'Anorak','Blazer','Blouse','Bomber','Button-Down','Cardigan',\n",
    "                'Flannel','Halter','Henley','Hoodie',\n",
    "                'Jacket','Jersey','Parka','Peacoat','Poncho','Sweater','Tank',\n",
    "                'Tee','Top','Turtleneck','Capris','Chinos','Culottes','Cutoffs','Gauchos',\n",
    "                'Jeans','Jeggings','Jodhpurs','Joggers','Leggings','Sarong','Shorts',\n",
    "                'Skirt','Sweatpants','Sweatshorts','Trunks','Caftan','Cape','Coat',\n",
    "                'Coverup','Dress','Jumpsuit','Kaftan','Kimono','Nightdress','Onesie',\n",
    "                'Robe','Romper','Shirtdress','Sundress']\n",
    "\n",
    "FILE_CATEGORY_MAP = \"../assets/json/category_map_deep.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Category Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "# Load VIDEOtag, COCO category 맵핑 데이타\n",
    "# COCO Model에서 검출된 class와 VIDEOtag에 미리 정해져 있는 class매칭을 위해 사용\n",
    "###################################################################\n",
    "map_data = open(FILE_CATEGORY_MAP).read()\n",
    "tmp_vt_coco_cate_map = json.loads(map_data)[\"categories\"]\n",
    "\n",
    "# NOTE : 빠른 검색을 위해 dictionary로 생성\n",
    "vt_coco_cate_map = {}\n",
    "for cate_data in tmp_vt_coco_cate_map:\n",
    "    vt_coco_cate_map[cate_data['id']] = cate_data\n",
    "\n",
    "\n",
    "json_data = open(args_input_json).read()\n",
    "data = json.loads(json_data)\n",
    "\n",
    "# NOTE : VIDEOtag Data (원본)\n",
    "vt_anno_ary = data['annotations']\n",
    "vt_img_ary = data['images']\n",
    "vt_cate_ary = data['categories']\n",
    "\n",
    "# NOTE : VIDEOtag Data (검색용)\n",
    "vt_anno_ids_of_imageids = {}\n",
    "vt_anno_dic = {}\n",
    "vt_cate_ary_dic = {}\n",
    "\n",
    "for anno in vt_anno_ary:\n",
    "    vt_anno_dic[anno['id']] = anno\n",
    "\n",
    "# for cate in vt_cate_map_ary:\n",
    "#     vt_cate_ary_dic[cate['id']] = cate\n",
    "\n",
    "for image in vt_img_ary:\n",
    "    anno_ids = []\n",
    "    image_id = image['id']\n",
    "\n",
    "    for anno in vt_anno_ary:\n",
    "        anno_img_id = anno['image_id']\n",
    "        anno_id = anno['id']\n",
    "        if anno_img_id == image_id:\n",
    "            anno_ids.append(anno_id)\n",
    "\n",
    "    vt_anno_ids_of_imageids[image_id] = anno_ids\n",
    "\n",
    "def getAnnosByImgId(img_id):\n",
    "    anno_ids = vt_anno_ids_of_imageids[img_id]\n",
    "    result = []\n",
    "    for anno_id in anno_ids:  \n",
    "        result.append(vt_anno_dic[anno_id])\n",
    "\n",
    "    return result\n",
    "\n",
    "def insertBboxToAnno(anno_id, bbox):\n",
    "    for anno in vt_anno_ary:\n",
    "        if anno['id'] == anno_id:\n",
    "            anno['bbox'] = bbox\n",
    "            return anno\n",
    "            break\n",
    "            \n",
    "print('complete - Load Category Map')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Image Detection Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/luke/Documents/ml_datasets/new/all/images/val2017/000000551821.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-0c79225b3b41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# img_path = '/Users/luke/Desktop/test_img/000000554156.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# img_path = '../dataset/deepfashion/images/100000021448.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_image_bgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#skimage.io.imread(img_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/github/milkplz/keras-retinanet/keras_retinanet/utils/image.py\u001b[0m in \u001b[0;36mread_image_bgr\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_image_bgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/envs/py362/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2543\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2544\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/luke/Documents/ml_datasets/new/all/images/val2017/000000551821.jpg'"
     ]
    }
   ],
   "source": [
    "img_path = '/Users/luke/Documents/ml_datasets/new/all/images/val2017/00000055182.jpg'\n",
    "# img_path = '/Users/luke/Documents/dev/github/milkplz/keras-retinanet/dataset/deepfashion/images/100000000032.jpg'\n",
    "# img_path = '/Users/luke/Desktop/test_img/000000554156.jpg'\n",
    "# img_path = '../dataset/deepfashion/images/100000021448.jpg'\n",
    "image = read_image_bgr(img_path)#skimage.io.imread(img_path)\n",
    "\n",
    "draw = image.copy()\n",
    "draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# preprocess image for network\n",
    "image = preprocess_image(image)\n",
    "image, scale = resize_image(image, min_side=600, max_side=1024)\n",
    "\n",
    "_, _, detections = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "\n",
    "predicted_labels = np.argmax(detections[0, :, 4:], axis=1)\n",
    "scores = detections[0, np.arange(detections.shape[1]), 4 + predicted_labels]\n",
    "\n",
    "\n",
    "# correct for image scale\n",
    "detections[0, :, :4] /= scale\n",
    "\n",
    "found_num = 0\n",
    "for idx, (label, score) in enumerate(zip(predicted_labels, scores)):\n",
    "    if score < 0.1:\n",
    "        continue\n",
    "\n",
    "    found_num += 1\n",
    "    b = detections[0, idx, :4].astype(int)\n",
    "    cv2.rectangle(draw, (b[0], b[1]), (b[2], b[3]), (0, 0, 255), 2)\n",
    "    caption = \"{} {:.3f}\".format(coco_class_names[label], score)\n",
    "    cv2.putText(draw, caption, (b[0], b[1] + 20), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 0), 2)\n",
    "    cv2.putText(draw, caption, (b[0], b[1] + 20), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 1)\n",
    "    \n",
    "if not found_num == 0:\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(draw)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIDEOtag Dataset에서 검출되는 모든 Object 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1081\n",
      "1/1081\n",
      "2/1081\n",
      "3/1081\n",
      "4/1081\n",
      "5/1081\n",
      "6/1081\n",
      "7/1081\n",
      "8/1081\n",
      "9/1081\n",
      "10/1081\n",
      "11/1081\n",
      "12/1081\n",
      "13/1081\n",
      "14/1081\n",
      "15/1081\n",
      "16/1081\n",
      "17/1081\n",
      "18/1081\n",
      "19/1081\n",
      "20/1081\n",
      "21/1081\n",
      "22/1081\n",
      "23/1081\n",
      "24/1081\n",
      "25/1081\n",
      "26/1081\n",
      "27/1081\n",
      "28/1081\n",
      "29/1081\n",
      "30/1081\n",
      "31/1081\n",
      "32/1081\n",
      "33/1081\n",
      "34/1081\n",
      "35/1081\n",
      "36/1081\n",
      "37/1081\n",
      "38/1081\n",
      "39/1081\n",
      "40/1081\n",
      "41/1081\n",
      "42/1081\n",
      "43/1081\n",
      "44/1081\n",
      "45/1081\n",
      "46/1081\n",
      "47/1081\n",
      "48/1081\n",
      "49/1081\n",
      "50/1081\n",
      "51/1081\n",
      "52/1081\n",
      "53/1081\n",
      "54/1081\n",
      "55/1081\n",
      "56/1081\n",
      "57/1081\n",
      "58/1081\n",
      "59/1081\n",
      "60/1081\n",
      "61/1081\n",
      "62/1081\n",
      "63/1081\n",
      "64/1081\n",
      "65/1081\n",
      "66/1081\n",
      "67/1081\n",
      "68/1081\n",
      "69/1081\n",
      "70/1081\n",
      "71/1081\n",
      "72/1081\n",
      "73/1081\n",
      "74/1081\n",
      "75/1081\n",
      "76/1081\n",
      "77/1081\n",
      "78/1081\n",
      "79/1081\n",
      "80/1081\n",
      "81/1081\n",
      "82/1081\n",
      "83/1081\n",
      "84/1081\n",
      "85/1081\n",
      "86/1081\n",
      "87/1081\n",
      "88/1081\n",
      "89/1081\n",
      "90/1081\n",
      "91/1081\n",
      "92/1081\n",
      "93/1081\n",
      "94/1081\n",
      "95/1081\n",
      "96/1081\n",
      "97/1081\n",
      "98/1081\n",
      "99/1081\n",
      "100/1081\n",
      "101/1081\n",
      "102/1081\n",
      "103/1081\n",
      "104/1081\n",
      "105/1081\n",
      "106/1081\n",
      "107/1081\n",
      "108/1081\n",
      "109/1081\n",
      "110/1081\n",
      "111/1081\n",
      "112/1081\n",
      "113/1081\n",
      "114/1081\n",
      "115/1081\n",
      "116/1081\n",
      "117/1081\n",
      "118/1081\n",
      "119/1081\n",
      "120/1081\n",
      "121/1081\n",
      "122/1081\n",
      "123/1081\n",
      "124/1081\n",
      "125/1081\n",
      "126/1081\n",
      "127/1081\n",
      "128/1081\n",
      "129/1081\n",
      "130/1081\n",
      "131/1081\n",
      "132/1081\n",
      "133/1081\n",
      "134/1081\n",
      "135/1081\n",
      "136/1081\n",
      "137/1081\n",
      "138/1081\n",
      "139/1081\n",
      "140/1081\n",
      "141/1081\n",
      "142/1081\n",
      "143/1081\n",
      "144/1081\n",
      "145/1081\n",
      "146/1081\n",
      "147/1081\n",
      "148/1081\n",
      "149/1081\n",
      "150/1081\n",
      "151/1081\n",
      "152/1081\n",
      "153/1081\n",
      "154/1081\n",
      "155/1081\n",
      "156/1081\n",
      "157/1081\n",
      "158/1081\n",
      "159/1081\n",
      "160/1081\n",
      "161/1081\n",
      "162/1081\n",
      "163/1081\n",
      "164/1081\n",
      "165/1081\n",
      "166/1081\n",
      "167/1081\n",
      "168/1081\n",
      "169/1081\n",
      "170/1081\n",
      "171/1081\n",
      "172/1081\n",
      "173/1081\n",
      "174/1081\n",
      "175/1081\n",
      "176/1081\n",
      "177/1081\n",
      "178/1081\n",
      "179/1081\n",
      "180/1081\n",
      "181/1081\n",
      "182/1081\n",
      "183/1081\n",
      "184/1081\n",
      "185/1081\n",
      "186/1081\n",
      "187/1081\n",
      "188/1081\n",
      "189/1081\n",
      "190/1081\n",
      "191/1081\n",
      "192/1081\n",
      "193/1081\n",
      "194/1081\n",
      "195/1081\n",
      "196/1081\n",
      "197/1081\n",
      "198/1081\n",
      "199/1081\n",
      "200/1081\n",
      "201/1081\n",
      "202/1081\n",
      "203/1081\n",
      "204/1081\n",
      "205/1081\n",
      "206/1081\n",
      "207/1081\n",
      "208/1081\n",
      "209/1081\n",
      "210/1081\n",
      "211/1081\n",
      "212/1081\n",
      "213/1081\n",
      "214/1081\n",
      "215/1081\n",
      "216/1081\n",
      "217/1081\n",
      "218/1081\n",
      "219/1081\n",
      "220/1081\n",
      "221/1081\n",
      "222/1081\n",
      "223/1081\n",
      "224/1081\n",
      "225/1081\n",
      "226/1081\n",
      "227/1081\n",
      "228/1081\n",
      "229/1081\n",
      "230/1081\n",
      "231/1081\n",
      "232/1081\n",
      "233/1081\n",
      "234/1081\n",
      "235/1081\n",
      "236/1081\n",
      "237/1081\n",
      "238/1081\n",
      "239/1081\n",
      "240/1081\n",
      "241/1081\n",
      "242/1081\n",
      "243/1081\n",
      "244/1081\n",
      "245/1081\n",
      "246/1081\n",
      "247/1081\n",
      "248/1081\n",
      "249/1081\n",
      "250/1081\n",
      "251/1081\n",
      "252/1081\n",
      "253/1081\n",
      "254/1081\n",
      "255/1081\n",
      "256/1081\n",
      "257/1081\n",
      "258/1081\n",
      "259/1081\n",
      "260/1081\n",
      "261/1081\n",
      "262/1081\n",
      "263/1081\n",
      "264/1081\n",
      "265/1081\n",
      "266/1081\n",
      "267/1081\n",
      "268/1081\n",
      "269/1081\n",
      "270/1081\n",
      "271/1081\n",
      "272/1081\n",
      "273/1081\n",
      "274/1081\n",
      "275/1081\n",
      "276/1081\n",
      "277/1081\n",
      "278/1081\n",
      "279/1081\n",
      "280/1081\n",
      "281/1081\n",
      "282/1081\n",
      "283/1081\n",
      "284/1081\n",
      "285/1081\n",
      "286/1081\n",
      "287/1081\n",
      "288/1081\n",
      "289/1081\n",
      "290/1081\n",
      "291/1081\n",
      "292/1081\n",
      "293/1081\n",
      "294/1081\n",
      "295/1081\n",
      "296/1081\n",
      "297/1081\n",
      "298/1081\n",
      "299/1081\n",
      "300/1081\n",
      "301/1081\n",
      "302/1081\n",
      "303/1081\n",
      "304/1081\n",
      "305/1081\n",
      "306/1081\n",
      "307/1081\n",
      "308/1081\n",
      "309/1081\n",
      "310/1081\n",
      "311/1081\n",
      "312/1081\n",
      "313/1081\n",
      "314/1081\n",
      "315/1081\n",
      "316/1081\n",
      "317/1081\n",
      "318/1081\n",
      "319/1081\n",
      "320/1081\n",
      "321/1081\n",
      "322/1081\n",
      "323/1081\n",
      "324/1081\n",
      "325/1081\n",
      "326/1081\n",
      "327/1081\n",
      "328/1081\n",
      "329/1081\n",
      "330/1081\n",
      "331/1081\n",
      "332/1081\n",
      "333/1081\n",
      "334/1081\n",
      "335/1081\n",
      "336/1081\n",
      "337/1081\n",
      "338/1081\n",
      "339/1081\n",
      "340/1081\n",
      "341/1081\n",
      "342/1081\n",
      "343/1081\n",
      "344/1081\n",
      "345/1081\n",
      "346/1081\n",
      "347/1081\n",
      "348/1081\n",
      "349/1081\n",
      "350/1081\n",
      "351/1081\n",
      "352/1081\n",
      "353/1081\n",
      "354/1081\n",
      "355/1081\n",
      "356/1081\n",
      "357/1081\n",
      "358/1081\n",
      "359/1081\n",
      "360/1081\n",
      "361/1081\n",
      "362/1081\n",
      "363/1081\n",
      "364/1081\n",
      "365/1081\n",
      "366/1081\n",
      "367/1081\n",
      "368/1081\n",
      "369/1081\n",
      "370/1081\n",
      "371/1081\n",
      "372/1081\n",
      "373/1081\n",
      "374/1081\n",
      "375/1081\n",
      "376/1081\n",
      "377/1081\n",
      "378/1081\n",
      "379/1081\n",
      "380/1081\n",
      "381/1081\n",
      "382/1081\n",
      "383/1081\n",
      "384/1081\n",
      "385/1081\n",
      "386/1081\n",
      "387/1081\n",
      "388/1081\n",
      "389/1081\n",
      "390/1081\n",
      "391/1081\n",
      "392/1081\n",
      "393/1081\n",
      "394/1081\n",
      "395/1081\n",
      "396/1081\n",
      "397/1081\n",
      "398/1081\n",
      "399/1081\n",
      "400/1081\n",
      "401/1081\n",
      "402/1081\n",
      "403/1081\n",
      "404/1081\n",
      "405/1081\n",
      "406/1081\n",
      "407/1081\n",
      "408/1081\n",
      "409/1081\n",
      "410/1081\n",
      "411/1081\n",
      "412/1081\n",
      "413/1081\n",
      "414/1081\n",
      "415/1081\n",
      "416/1081\n",
      "417/1081\n",
      "418/1081\n",
      "419/1081\n",
      "420/1081\n",
      "421/1081\n",
      "422/1081\n",
      "423/1081\n",
      "424/1081\n",
      "425/1081\n",
      "426/1081\n",
      "427/1081\n",
      "428/1081\n",
      "429/1081\n",
      "430/1081\n",
      "431/1081\n",
      "432/1081\n",
      "433/1081\n",
      "434/1081\n",
      "435/1081\n",
      "436/1081\n",
      "437/1081\n",
      "438/1081\n",
      "439/1081\n",
      "440/1081\n",
      "441/1081\n",
      "442/1081\n",
      "443/1081\n",
      "444/1081\n",
      "445/1081\n",
      "446/1081\n",
      "447/1081\n",
      "448/1081\n",
      "449/1081\n",
      "450/1081\n",
      "451/1081\n",
      "452/1081\n",
      "453/1081\n",
      "454/1081\n",
      "455/1081\n",
      "456/1081\n",
      "457/1081\n",
      "458/1081\n",
      "459/1081\n",
      "460/1081\n",
      "461/1081\n",
      "462/1081\n",
      "463/1081\n",
      "464/1081\n",
      "465/1081\n",
      "466/1081\n",
      "467/1081\n",
      "468/1081\n",
      "469/1081\n",
      "470/1081\n",
      "471/1081\n",
      "472/1081\n",
      "473/1081\n",
      "474/1081\n",
      "475/1081\n",
      "476/1081\n",
      "477/1081\n",
      "478/1081\n",
      "479/1081\n",
      "480/1081\n",
      "481/1081\n",
      "482/1081\n",
      "483/1081\n",
      "484/1081\n",
      "485/1081\n",
      "486/1081\n",
      "487/1081\n",
      "488/1081\n",
      "489/1081\n",
      "490/1081\n",
      "491/1081\n",
      "492/1081\n",
      "493/1081\n",
      "494/1081\n",
      "495/1081\n",
      "496/1081\n",
      "497/1081\n",
      "498/1081\n",
      "499/1081\n",
      "500/1081\n",
      "501/1081\n",
      "502/1081\n",
      "503/1081\n",
      "504/1081\n",
      "505/1081\n",
      "506/1081\n",
      "507/1081\n",
      "508/1081\n",
      "509/1081\n",
      "510/1081\n",
      "511/1081\n",
      "512/1081\n",
      "513/1081\n",
      "514/1081\n",
      "515/1081\n",
      "516/1081\n",
      "517/1081\n",
      "518/1081\n",
      "519/1081\n",
      "520/1081\n",
      "521/1081\n",
      "522/1081\n",
      "523/1081\n",
      "524/1081\n",
      "525/1081\n",
      "526/1081\n",
      "527/1081\n",
      "528/1081\n",
      "529/1081\n",
      "530/1081\n",
      "531/1081\n",
      "532/1081\n",
      "533/1081\n",
      "534/1081\n",
      "535/1081\n",
      "536/1081\n",
      "537/1081\n",
      "538/1081\n",
      "539/1081\n",
      "540/1081\n",
      "541/1081\n",
      "542/1081\n",
      "543/1081\n",
      "544/1081\n",
      "545/1081\n",
      "546/1081\n",
      "547/1081\n",
      "548/1081\n",
      "549/1081\n",
      "550/1081\n",
      "551/1081\n",
      "552/1081\n",
      "553/1081\n",
      "554/1081\n",
      "555/1081\n",
      "556/1081\n",
      "557/1081\n",
      "558/1081\n",
      "559/1081\n",
      "560/1081\n",
      "561/1081\n",
      "562/1081\n",
      "563/1081\n",
      "564/1081\n",
      "565/1081\n",
      "566/1081\n",
      "567/1081\n",
      "568/1081\n",
      "569/1081\n",
      "570/1081\n",
      "571/1081\n",
      "572/1081\n",
      "573/1081\n",
      "574/1081\n",
      "575/1081\n",
      "576/1081\n",
      "577/1081\n",
      "578/1081\n",
      "579/1081\n",
      "580/1081\n",
      "581/1081\n",
      "582/1081\n",
      "583/1081\n",
      "584/1081\n",
      "585/1081\n",
      "586/1081\n",
      "587/1081\n",
      "588/1081\n",
      "589/1081\n",
      "590/1081\n",
      "591/1081\n",
      "592/1081\n",
      "593/1081\n",
      "594/1081\n",
      "595/1081\n",
      "596/1081\n",
      "597/1081\n",
      "598/1081\n",
      "599/1081\n",
      "600/1081\n",
      "601/1081\n",
      "602/1081\n",
      "603/1081\n",
      "604/1081\n",
      "605/1081\n",
      "606/1081\n",
      "607/1081\n",
      "608/1081\n",
      "609/1081\n",
      "610/1081\n",
      "611/1081\n",
      "612/1081\n",
      "613/1081\n",
      "614/1081\n",
      "615/1081\n",
      "616/1081\n",
      "617/1081\n",
      "618/1081\n",
      "619/1081\n",
      "620/1081\n",
      "621/1081\n",
      "622/1081\n",
      "623/1081\n",
      "624/1081\n",
      "625/1081\n",
      "626/1081\n",
      "627/1081\n",
      "628/1081\n",
      "629/1081\n",
      "630/1081\n",
      "631/1081\n",
      "632/1081\n",
      "633/1081\n",
      "634/1081\n",
      "635/1081\n",
      "636/1081\n",
      "637/1081\n",
      "638/1081\n",
      "639/1081\n",
      "640/1081\n",
      "641/1081\n",
      "642/1081\n",
      "643/1081\n",
      "644/1081\n",
      "645/1081\n",
      "646/1081\n",
      "647/1081\n",
      "648/1081\n",
      "649/1081\n",
      "650/1081\n",
      "651/1081\n",
      "652/1081\n",
      "653/1081\n",
      "654/1081\n",
      "655/1081\n",
      "656/1081\n",
      "657/1081\n",
      "658/1081\n",
      "659/1081\n",
      "660/1081\n",
      "661/1081\n",
      "662/1081\n",
      "663/1081\n",
      "664/1081\n",
      "665/1081\n",
      "666/1081\n",
      "667/1081\n",
      "668/1081\n",
      "669/1081\n",
      "670/1081\n",
      "671/1081\n",
      "672/1081\n",
      "673/1081\n",
      "674/1081\n",
      "675/1081\n",
      "676/1081\n",
      "677/1081\n",
      "678/1081\n",
      "679/1081\n",
      "680/1081\n",
      "681/1081\n",
      "682/1081\n",
      "683/1081\n",
      "684/1081\n",
      "685/1081\n",
      "686/1081\n",
      "687/1081\n",
      "688/1081\n",
      "689/1081\n",
      "690/1081\n",
      "691/1081\n",
      "692/1081\n",
      "693/1081\n",
      "694/1081\n",
      "695/1081\n",
      "696/1081\n",
      "697/1081\n",
      "698/1081\n",
      "699/1081\n",
      "700/1081\n",
      "701/1081\n",
      "702/1081\n",
      "703/1081\n",
      "704/1081\n",
      "705/1081\n",
      "706/1081\n",
      "707/1081\n",
      "708/1081\n",
      "709/1081\n",
      "710/1081\n",
      "711/1081\n",
      "712/1081\n",
      "713/1081\n",
      "714/1081\n",
      "715/1081\n",
      "716/1081\n",
      "717/1081\n",
      "718/1081\n",
      "719/1081\n",
      "720/1081\n",
      "721/1081\n",
      "722/1081\n",
      "723/1081\n",
      "724/1081\n",
      "725/1081\n",
      "726/1081\n",
      "727/1081\n",
      "728/1081\n",
      "729/1081\n",
      "730/1081\n",
      "731/1081\n",
      "732/1081\n",
      "733/1081\n",
      "734/1081\n",
      "735/1081\n",
      "736/1081\n",
      "737/1081\n",
      "738/1081\n",
      "739/1081\n",
      "740/1081\n",
      "741/1081\n",
      "742/1081\n",
      "743/1081\n",
      "744/1081\n",
      "745/1081\n",
      "746/1081\n",
      "747/1081\n",
      "748/1081\n",
      "749/1081\n",
      "750/1081\n",
      "751/1081\n",
      "752/1081\n",
      "753/1081\n",
      "754/1081\n",
      "755/1081\n",
      "756/1081\n",
      "757/1081\n",
      "758/1081\n",
      "759/1081\n",
      "760/1081\n",
      "761/1081\n",
      "762/1081\n",
      "763/1081\n",
      "764/1081\n",
      "765/1081\n",
      "766/1081\n",
      "767/1081\n",
      "768/1081\n",
      "769/1081\n",
      "770/1081\n",
      "771/1081\n",
      "772/1081\n",
      "773/1081\n",
      "774/1081\n",
      "775/1081\n",
      "776/1081\n",
      "777/1081\n",
      "778/1081\n",
      "779/1081\n",
      "780/1081\n",
      "781/1081\n",
      "782/1081\n",
      "783/1081\n",
      "784/1081\n",
      "785/1081\n",
      "786/1081\n",
      "787/1081\n",
      "788/1081\n",
      "789/1081\n",
      "790/1081\n",
      "791/1081\n",
      "792/1081\n",
      "793/1081\n",
      "794/1081\n",
      "795/1081\n",
      "796/1081\n",
      "797/1081\n",
      "798/1081\n",
      "799/1081\n",
      "800/1081\n",
      "801/1081\n",
      "802/1081\n",
      "803/1081\n",
      "804/1081\n",
      "805/1081\n",
      "806/1081\n",
      "807/1081\n",
      "808/1081\n",
      "809/1081\n",
      "810/1081\n",
      "811/1081\n",
      "812/1081\n",
      "813/1081\n",
      "814/1081\n",
      "815/1081\n",
      "816/1081\n",
      "817/1081\n",
      "818/1081\n",
      "819/1081\n",
      "820/1081\n",
      "821/1081\n",
      "822/1081\n",
      "823/1081\n",
      "824/1081\n",
      "825/1081\n",
      "826/1081\n",
      "827/1081\n",
      "828/1081\n",
      "829/1081\n",
      "830/1081\n",
      "831/1081\n",
      "832/1081\n",
      "833/1081\n",
      "834/1081\n",
      "835/1081\n",
      "836/1081\n",
      "837/1081\n",
      "838/1081\n",
      "839/1081\n",
      "840/1081\n",
      "841/1081\n",
      "842/1081\n",
      "843/1081\n",
      "844/1081\n",
      "845/1081\n",
      "846/1081\n",
      "847/1081\n",
      "848/1081\n",
      "849/1081\n",
      "850/1081\n",
      "851/1081\n",
      "852/1081\n",
      "853/1081\n",
      "854/1081\n",
      "855/1081\n",
      "856/1081\n",
      "857/1081\n",
      "858/1081\n",
      "859/1081\n",
      "860/1081\n",
      "861/1081\n",
      "862/1081\n",
      "863/1081\n",
      "864/1081\n",
      "865/1081\n",
      "866/1081\n",
      "867/1081\n",
      "868/1081\n",
      "869/1081\n",
      "870/1081\n",
      "871/1081\n",
      "872/1081\n",
      "873/1081\n",
      "874/1081\n",
      "875/1081\n",
      "876/1081\n",
      "877/1081\n",
      "878/1081\n",
      "879/1081\n",
      "880/1081\n",
      "881/1081\n",
      "882/1081\n",
      "883/1081\n",
      "884/1081\n",
      "885/1081\n",
      "886/1081\n",
      "887/1081\n",
      "888/1081\n",
      "889/1081\n",
      "890/1081\n",
      "891/1081\n",
      "892/1081\n",
      "893/1081\n",
      "894/1081\n",
      "895/1081\n",
      "896/1081\n",
      "897/1081\n",
      "898/1081\n",
      "899/1081\n",
      "900/1081\n",
      "901/1081\n",
      "902/1081\n",
      "903/1081\n",
      "904/1081\n",
      "905/1081\n",
      "906/1081\n",
      "907/1081\n",
      "908/1081\n",
      "909/1081\n",
      "910/1081\n",
      "911/1081\n",
      "912/1081\n",
      "913/1081\n",
      "914/1081\n",
      "915/1081\n",
      "916/1081\n",
      "917/1081\n",
      "918/1081\n",
      "919/1081\n",
      "920/1081\n",
      "921/1081\n",
      "922/1081\n",
      "923/1081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "924/1081\n",
      "925/1081\n",
      "926/1081\n",
      "927/1081\n",
      "928/1081\n",
      "929/1081\n",
      "930/1081\n",
      "931/1081\n",
      "932/1081\n",
      "933/1081\n",
      "934/1081\n",
      "935/1081\n",
      "936/1081\n",
      "937/1081\n",
      "938/1081\n",
      "939/1081\n",
      "940/1081\n",
      "941/1081\n",
      "942/1081\n",
      "943/1081\n",
      "944/1081\n",
      "945/1081\n",
      "946/1081\n",
      "947/1081\n",
      "948/1081\n",
      "949/1081\n",
      "950/1081\n",
      "951/1081\n",
      "952/1081\n",
      "953/1081\n",
      "954/1081\n",
      "955/1081\n",
      "956/1081\n",
      "957/1081\n",
      "958/1081\n",
      "959/1081\n",
      "960/1081\n",
      "961/1081\n",
      "962/1081\n",
      "963/1081\n",
      "964/1081\n",
      "965/1081\n",
      "966/1081\n",
      "967/1081\n",
      "968/1081\n",
      "969/1081\n",
      "970/1081\n",
      "971/1081\n",
      "972/1081\n",
      "973/1081\n",
      "974/1081\n",
      "975/1081\n",
      "976/1081\n",
      "977/1081\n",
      "978/1081\n",
      "979/1081\n",
      "980/1081\n",
      "981/1081\n",
      "982/1081\n",
      "983/1081\n",
      "984/1081\n",
      "985/1081\n",
      "986/1081\n",
      "987/1081\n",
      "988/1081\n",
      "989/1081\n",
      "990/1081\n",
      "991/1081\n",
      "992/1081\n",
      "993/1081\n",
      "994/1081\n",
      "995/1081\n",
      "996/1081\n",
      "997/1081\n",
      "998/1081\n",
      "999/1081\n",
      "1000/1081\n",
      "1001/1081\n",
      "1002/1081\n",
      "1003/1081\n",
      "1004/1081\n",
      "1005/1081\n",
      "1006/1081\n",
      "1007/1081\n",
      "1008/1081\n",
      "1009/1081\n",
      "1010/1081\n",
      "1011/1081\n",
      "1012/1081\n",
      "1013/1081\n",
      "1014/1081\n",
      "1015/1081\n",
      "1016/1081\n",
      "1017/1081\n",
      "1018/1081\n",
      "1019/1081\n",
      "1020/1081\n",
      "1021/1081\n",
      "1022/1081\n",
      "1023/1081\n",
      "1024/1081\n",
      "1025/1081\n",
      "1026/1081\n",
      "1027/1081\n",
      "1028/1081\n",
      "1029/1081\n",
      "1030/1081\n",
      "1031/1081\n",
      "1032/1081\n",
      "1033/1081\n",
      "1034/1081\n",
      "1035/1081\n",
      "1036/1081\n",
      "1037/1081\n",
      "1038/1081\n",
      "1039/1081\n",
      "1040/1081\n",
      "1041/1081\n",
      "1042/1081\n",
      "1043/1081\n",
      "1044/1081\n",
      "1045/1081\n",
      "1046/1081\n",
      "1047/1081\n",
      "1048/1081\n",
      "1049/1081\n",
      "1050/1081\n",
      "1051/1081\n",
      "1052/1081\n",
      "1053/1081\n",
      "1054/1081\n",
      "1055/1081\n",
      "1056/1081\n",
      "1057/1081\n",
      "1058/1081\n",
      "1059/1081\n",
      "1060/1081\n",
      "1061/1081\n",
      "1062/1081\n",
      "1063/1081\n",
      "1064/1081\n",
      "1065/1081\n",
      "1066/1081\n",
      "1067/1081\n",
      "1068/1081\n",
      "1069/1081\n",
      "1070/1081\n",
      "1071/1081\n",
      "1072/1081\n",
      "1073/1081\n",
      "1074/1081\n",
      "1075/1081\n",
      "1076/1081\n",
      "1077/1081\n",
      "1078/1081\n",
      "1079/1081\n",
      "1080/1081\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "\n",
    "\n",
    "###################################################################\n",
    "# 모든 이미지에 대하여 predict를 실시한다.\n",
    "###################################################################\n",
    "img_total = len(vt_img_ary)\n",
    "\n",
    "for img_idx, img_data in enumerate(vt_img_ary): \n",
    "    # NOTE : d_ -> detected_, a_ -> answer_\n",
    "    \n",
    "    print(str(img_idx)+'/'+str(img_total))\n",
    "    img_id = img_data['id']\n",
    "\n",
    "    ###################################################################\n",
    "    # videotag image에 등록되어 있느 annotation이 있는지 확인 후, 로드\n",
    "    ###################################################################\n",
    "    a_vt_annos = getAnnosByImgId(img_id)\n",
    "\n",
    "    if len(a_vt_annos) == 0:\n",
    "        continue\n",
    "\n",
    "    ###################################################################\n",
    "    # videotag image 로드\n",
    "    ###################################################################\n",
    "    img_path = os.path.join(ROOT_DIR, args_image_dir, img_data['file_name']) \n",
    "    image = read_image_bgr(img_path)\n",
    "    img_height, img_width = image.shape[:2]\n",
    "    draw = image.copy()\n",
    "    draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # preprocess image for network\n",
    "    image = preprocess_image(image)\n",
    "    image, scale = resize_image(image, min_side=600, max_side=1024)\n",
    "    \n",
    "    ###################################################################\n",
    "    # Run detection\n",
    "    ###################################################################\n",
    "    _, _, detections = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "    \n",
    "    predicted_labels = np.argmax(detections[0, :, 4:], axis=1)\n",
    "    scores = detections[0, np.arange(detections.shape[1]), 4 + predicted_labels]\n",
    "\n",
    "    # correct for image scale\n",
    "    detections[0, :, :4] /= scale\n",
    "    \n",
    "    found_num = 0\n",
    "    for idx, (label, score) in enumerate(zip(predicted_labels, scores)):\n",
    "        if score < 0.2:\n",
    "            continue\n",
    "            \n",
    "        found_num += 1\n",
    "        b = detections[0, idx, :4].astype(int)\n",
    "        cv2.rectangle(draw, (b[0], b[1]), (b[2], b[3]), (0, 0, 255), 3)\n",
    "#         caption = \"{} {:.3f}\".format(coco_class_names[label+1], score) # coco + deepfashion\n",
    "#         caption = \"{} {:.3f}\".format(coco_class_names[label-1], score) # deepfahsion\n",
    "        caption = \"{} {:.3f}\".format(coco_class_names[label], score) # deepfahsion(category3)\n",
    "        cv2.putText(draw, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 0), 3)\n",
    "        cv2.putText(draw, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 255), 2)\n",
    "        \n",
    "        \n",
    "    if not found_num == 0:\n",
    "        save_path = os.path.join(ROOT_DIR, args_image_log_dir, \"deep\", str(img_idx+100000000000).zfill(12)+'.jpg') \n",
    "        imageio.imwrite(save_path, draw)\n",
    "        \n",
    "#         plt.figure(figsize=(15, 15))\n",
    "#         plt.axis('off')\n",
    "#         plt.imshow(draw)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection, VIDEOtag Points 모두 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-a597d67d64c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Run detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m###################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0md_coco_cate_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#d_r['class_ids']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1950\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1952\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1953\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###################################################################\n",
    "# 모든 이미지에 대하여 predict를 실시한다.\n",
    "###################################################################\n",
    "img_total = len(vt_img_ary)\n",
    "\n",
    "for img_idx, img_data in enumerate(vt_img_ary): \n",
    "    # NOTE : d_ -> detected_, a_ -> answer_\n",
    "    \n",
    "#     if img_idx < 6:\n",
    "#         continue\n",
    "        \n",
    "#     if img_idx > 100:\n",
    "#         break\n",
    "\n",
    "    img_id = img_data['id']\n",
    "\n",
    "    ###################################################################\n",
    "    # videotag image에 등록되어 있느 annotation이 있는지 확인 후, 로드\n",
    "    ###################################################################\n",
    "    a_vt_annos = getAnnosByImgId(img_id)\n",
    "\n",
    "    if len(a_vt_annos) == 0:\n",
    "        continue\n",
    "\n",
    "    ###################################################################\n",
    "    # videotag image이 로드\n",
    "    ###################################################################\n",
    "    img_path = os.path.join(ROOT_DIR, args_image_dir, img_data['file_name']) \n",
    "    image = read_image_bgr(img_path)\n",
    "    img_height, img_width = image.shape[:2]\n",
    "    \n",
    "    draw = image.copy()\n",
    "    draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # preprocess image for network\n",
    "    image = preprocess_image(image)\n",
    "    image, scale = resize_image(image, min_side=600, max_side=1024)\n",
    "    \n",
    "    ###################################################################\n",
    "    # Run detection\n",
    "    ###################################################################\n",
    "    _, _, detections = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "    \n",
    "    d_coco_cate_ids = np.argmax(detections[0, :, 4:], axis=1)#d_r['class_ids']\n",
    "    d_scores = detections[0, np.arange(detections.shape[1]), 4 + d_coco_cate_ids]#d_r['scores']\n",
    "\n",
    "    # correct for image scale\n",
    "    detections[0, :, :4] /= scale\n",
    "\n",
    "    # 확인용\n",
    "    confirm_matching_classes = []\n",
    "    confirm_vt_anno_points = []\n",
    "\n",
    "    is_found = 0\n",
    "    \n",
    "    \n",
    "    ###################################################################\n",
    "    # Detection 표시\n",
    "    ###################################################################\n",
    "    for idx, (label, score) in enumerate(zip(d_coco_cate_ids, d_scores)):\n",
    "        if score < 0.2:\n",
    "            continue\n",
    "            \n",
    "        found_num += 1\n",
    "        b = detections[0, idx, :4].astype(int)\n",
    "        print('Detection bbox', b[0], b[1], b[2], b[3])\n",
    "        cv2.rectangle(draw, (b[0], b[1]), (b[2], b[3]), (0, 0, 255), 3)\n",
    "#         caption = \"{} {:.3f}\".format(coco_class_names[label+1], score) # coco, coco+deep\n",
    "        caption = \"{} {:.3f}\".format(coco_class_names[label-1], score) # deep\n",
    "        cv2.putText(draw, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 0), 3)\n",
    "        cv2.putText(draw, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 255), 2)\n",
    "    \n",
    "    \n",
    "   \n",
    "        \n",
    "    ###################################################################\n",
    "    # VIDEOtag Point 출력\n",
    "    ###################################################################\n",
    "    for a_vt_anno in a_vt_annos:\n",
    "        a_vt_anno_id = a_vt_anno['id']\n",
    "        a_vt_cate_id = a_vt_anno['category_id']\n",
    "        a_vt_cate_name = vt_coco_cate_map[a_vt_cate_id]['name']\n",
    "\n",
    "        point_x = int(img_width * a_vt_anno['x_pos'])\n",
    "        point_y = int(img_height * a_vt_anno['y_pos'])\n",
    "        print('videotag', img_width, img_height, point_x, point_y)\n",
    "        cv2.rectangle(draw, (point_x-5, point_y-5), (point_x+5, point_y+5), (255, 0, 0), 3)\n",
    "        caption = \"{}\".format(a_vt_cate_name)\n",
    "        cv2.putText(draw, caption, (point_x, point_y-10), cv2.FONT_HERSHEY_PLAIN, 1.5, (255, 0, 0), 3)\n",
    "        print(a_vt_cate_id, a_vt_cate_name)\n",
    "                \n",
    "#     plt.figure(figsize=(15, 15))\n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(draw)\n",
    "#     plt.show()\n",
    "    \n",
    "    save_path = os.path.join(ROOT_DIR, args_image_log_dir, 'deep', str(img_idx+100000000000).zfill(12)+'.jpg') \n",
    "    imageio.imwrite(save_path, draw)\n",
    "\n",
    "    if len(confirm_matching_classes) > 0:\n",
    "        print('매칭된 카테고리 확인 - ', confirm_matching_classes)\n",
    "        print('----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bbox 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/1081\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-dc27ec3e9875>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# Run detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m###################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0md_coco_cate_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#d_r['class_ids']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1950\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1952\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1953\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###################################################################\n",
    "# 모든 이미지에 대하여 predict를 실시한다.\n",
    "###################################################################\n",
    "img_total = len(vt_img_ary)\n",
    "\n",
    "for img_idx, img_data in enumerate(vt_img_ary): \n",
    "    # NOTE : d_ -> detected_, a_ -> answer_\n",
    "    \n",
    "    if img_idx < 6:\n",
    "        continue\n",
    "        \n",
    "#     if img_idx > 100:\n",
    "#         break\n",
    "\n",
    "    print(str(img_idx)+'/'+str(img_total))\n",
    "    img_id = img_data['id']\n",
    "\n",
    "    ###################################################################\n",
    "    # videotag image에 등록되어 있느 annotation이 있는지 확인 후, 로드\n",
    "    ###################################################################\n",
    "    a_vt_annos = getAnnosByImgId(img_id)\n",
    "\n",
    "    if len(a_vt_annos) == 0:\n",
    "        continue\n",
    "\n",
    "    ###################################################################\n",
    "    # videotag image이 로드\n",
    "    ###################################################################\n",
    "    img_path = os.path.join(ROOT_DIR, args_image_dir, img_data['file_name']) \n",
    "    image = read_image_bgr(img_path)\n",
    "    img_height, img_width = image.shape[:2]\n",
    "    \n",
    "    draw = image.copy()\n",
    "    draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # preprocess image for network\n",
    "    image = preprocess_image(image)\n",
    "    image, scale = resize_image(image, min_side=600, max_side=1024)\n",
    "    \n",
    "    ###################################################################\n",
    "    # Run detection\n",
    "    ###################################################################\n",
    "    _, _, detections = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "    \n",
    "    d_coco_cate_ids = np.argmax(detections[0, :, 4:], axis=1)#d_r['class_ids']\n",
    "    d_scores = detections[0, np.arange(detections.shape[1]), 4 + d_coco_cate_ids]#d_r['scores']\n",
    "\n",
    "    # correct for image scale\n",
    "    detections[0, :, :4] /= scale\n",
    "\n",
    "    # 확인용\n",
    "    confirm_matching_classes = []\n",
    "    confirm_vt_anno_points = []\n",
    "\n",
    "    is_found = 0\n",
    "    \n",
    "#     draw = image.copy()\n",
    "\n",
    "    ###################################################################\n",
    "    # 추출된 data를 VIDEOtag Annotation과 비교\n",
    "    ###################################################################\n",
    "    for d_idx, score in enumerate(d_scores):\n",
    "        '''\n",
    "        스코어 낮은 것은 의미가 없는 것으로 판단함\n",
    "        아래에 VIDEOtag과 COCO의 데이타를 비교하는 로직이 있으므로 Predict의 정확도는\n",
    "        현재 로직에서 의미가 없음\n",
    "        '''\n",
    "        \n",
    "        if score < 0.2:\n",
    "            continue\n",
    "\n",
    "        d_coco_cate_id = d_coco_cate_ids[d_idx]\n",
    "        d_coco_cate_name = coco_class_names[d_coco_cate_id-1]\n",
    "        y1, x1, y2, x2 = detections[0, d_idx, :4].astype(int)\n",
    "        d_bbox = [int(x1), int(y1), int(x2 - x1), int(y2 - y1)]\n",
    "        \n",
    "        ###################################################################\n",
    "        # coco model에서 검출된 annotation들이 videotag annotation(정답)들과 비교하여\n",
    "        # 일치할 경우가 있을 때, 해당 videotag annotation에 bbox정보를 추가한다.\n",
    "        ###################################################################\n",
    "        for a_vt_anno in a_vt_annos:\n",
    "            a_vt_anno_id = a_vt_anno['id']\n",
    "            a_vt_cate_id = a_vt_anno['category_id']\n",
    "            a_vt_cate_name = vt_coco_cate_map[a_vt_cate_id]['name']\n",
    "\n",
    "            point_x = int(img_width * a_vt_anno['x_pos'])\n",
    "            point_y = int(img_height * a_vt_anno['y_pos'])\n",
    "\n",
    "            # NOTE : 기대하는 VIDEOtag의 coco categories 확인. 현재(2018.02) 매칭되는 category가 많지 않다.\n",
    "            a_coco_cate_ids = vt_coco_cate_map[a_vt_cate_id]['coco_ids']\n",
    "            if len(a_coco_cate_ids) == 0:\n",
    "                continue\n",
    "                \n",
    "            # NOTE: 포인트가 마스크 영역에 속하는 확인\n",
    "            if point_x < x1 or point_x > x2 or point_y < y1 or point_y > y2:\n",
    "                continue\n",
    "\n",
    "            for a_coco_cate_id in a_coco_cate_ids:\n",
    "                if a_coco_cate_id == d_coco_cate_id:\n",
    "                    insertBboxToAnno(a_vt_anno_id, d_bbox)\n",
    "                    \n",
    "                    confirm_vt_anno_points.append([point_y-5, point_x-5, point_y+5, point_x+5])\n",
    "                    confirm_matching_classes.append([d_coco_cate_name, a_vt_cate_name])\n",
    "                    \n",
    "                    cv2.rectangle(draw, (y1, x1), (y2, x2), (0, 0, 255), 3)\n",
    "                    caption = \"{} {:.3f}\".format(d_coco_cate_name, score)\n",
    "                    cv2.putText(draw, caption, (y1, x1 - 10), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 255), 2)\n",
    "                    cv2.rectangle(draw, (point_x-5, point_y-5), (point_x+5, point_y+5), (0, 0, 255), 3)\n",
    "                    cv2.putText(draw, a_vt_cate_id, (point_x, point_y - 10), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 255), 2)\n",
    "                    \n",
    "                    is_found = 1\n",
    "                    break\n",
    "                \n",
    "    if len(confirm_vt_anno_points) > 0:\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        plt.axis('off')\n",
    "        plt.imshow(draw)\n",
    "        plt.show()\n",
    "\n",
    "    if len(confirm_matching_classes) > 0:\n",
    "        print('매칭된 카테고리 확인 - ', confirm_matching_classes)\n",
    "        print('----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## result_json = {}\n",
    "result_json['annotations'] = vt_anno_ary\n",
    "result_json['images'] = vt_img_ary\n",
    "\n",
    "with open('../dataset/videotag/0101_0102/result/instances.json', 'w') as outfile:\n",
    "    json.dump(result_json, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
