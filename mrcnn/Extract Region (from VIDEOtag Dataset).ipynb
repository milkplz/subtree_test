{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import coco\n",
    "import utils\n",
    "import model as modellib\n",
    "from model import log\n",
    "import coco\n",
    "import visualize\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pycocotools import mask as maskUtils\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "IMAGE_DIR = \"/Users/luke/Documents/ml_datasets/new/videotag/0101_0102/images\"\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model & Load Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "# config.display()\n",
    "\n",
    "# Create model object in inference mode.\n",
    "model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir=MODEL_DIR)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare COCO categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO Class names\n",
    "# Index of the class in the list is its ID. For example, to get ID of\n",
    "# the teddy bear class, use: class_names.index('teddy bear')\n",
    "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "               'teddy bear', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare VIDEOtag, COCO category 맵핑 데이타"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VIDEOtag, COCO category 맵핑 데이타\n",
    "map_data = open(\"assets/json/category.json\").read()\n",
    "tmp_videotag_coco_cate_map = json.loads(map_data)[\"categories\"]\n",
    "\n",
    "# dictionary로 생성\n",
    "videotag_coco_cate_map = {}\n",
    "for cate_data in tmp_videotag_coco_cate_map:\n",
    "    videotag_coco_cate_map[cate_data['id']] = cate_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare VIDEOtag Dataset\n",
    "\n",
    "### 0101~0102 dataset\n",
    "https://s3.ap-northeast-2.amazonaws.com/f-machine-learning-dataset/datasets/fingerplus/0101_0102.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = open(\"/Users/luke/Documents/ml_datasets/new/videotag/0101_0102/instances.json\").read()\n",
    "data = json.loads(json_data)\n",
    "\n",
    "videotag_anno = data['annotations']\n",
    "videotag_imgs = data['images']\n",
    "videotag_cate = data['categories']\n",
    "\n",
    "videotag_img_anno_ids = {}\n",
    "videotag_anno_dic = {}\n",
    "videotag_cate_dic = {}\n",
    "\n",
    "for anno in videotag_anno:\n",
    "    videotag_anno_dic[anno['id']] = anno\n",
    "    \n",
    "for cate in videotag_cate:\n",
    "    videotag_cate_dic[cate['id']] = cate\n",
    "        \n",
    "for image in videotag_imgs:\n",
    "    anno_ids = []\n",
    "    image_id = image['id']\n",
    "    \n",
    "    for anno in videotag_anno:\n",
    "        anno_img_id = anno['image_id']\n",
    "        anno_id = anno['id']\n",
    "        if anno_img_id == image_id:\n",
    "            anno_ids.append(anno_id)\n",
    "    # if not len(annos) == 0:\n",
    "    videotag_img_anno_ids[image_id] = anno_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199606\n",
      "['297282', '297283']\n"
     ]
    }
   ],
   "source": [
    "print(videotag_imgs[1]['id'])\n",
    "print(videotag_img_anno_ids[videotag_imgs[1]['id']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect & Extract Region\n",
    "\n",
    "annotations : [{\n",
    "  area,         // Number - 영역 넓이(w*h)\n",
    "  bbox,         // [x,y,width,height], (Array(4))\n",
    "  category_id,  // int\n",
    "  id,           // int\n",
    "  image_id,     // int\n",
    "  iscrowd,      // 0 or 1 (get anns for given crowd label (False or True))\n",
    "  segmentation  // Array - mask 데이터 (RLE or [polygon])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1081\n",
      "1/1081\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: b'Y_`0Q1W:0000000000000O1O2N1O7H2O1N2N2N2N2N2N2O1O1O1O1O1O1O1O1N2N2N2M3M3N2H8J6J6J6K5M3L4M3L4L4K5K5J6K5M3M3N2O1O1O100000000000000000000000000000000001O001O001O1O001O1O1O1O1O001O1O1O1O2N2N:F2N3M2N2N4L4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-19119ac910f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0msegm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaskUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masfortranarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mrles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaskUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrPyObjects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mrle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaskUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;31m#         rle = maskUtils.decode(segmentation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/dev/github/milkplz/Mask_RCNN/pycocotools/_mask.pyx\u001b[0m in \u001b[0;36mpycocotools._mask.frPyObjects\u001b[0;34m()\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mobjs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrPoly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpyobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'counts'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpyobj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'size'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpyobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0mobjs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrUncompressedRLE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpyobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input type is not supported.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/dev/github/milkplz/Mask_RCNN/pycocotools/_mask.pyx\u001b[0m in \u001b[0;36mpycocotools._mask.frUncompressedRLE\u001b[0;34m()\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mRs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRLEs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0mcnts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mucRles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'counts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m         \u001b[0;31m# time for malloc can be saved here but it's fine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0muint\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mmalloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0msizeof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: b'Y_`0Q1W:0000000000000O1O2N1O7H2O1N2N2N2N2N2N2O1O1O1O1O1O1O1O1N2N2N2M3M3N2H8J6J6J6K5M3L4M3L4L4K5K5J6K5M3M3N2O1O1O100000000000000000000000000000000001O001O001O1O001O1O1O1O1O001O1O1O1O2N2N:F2N3M2N2N4L4"
     ]
    }
   ],
   "source": [
    "def getAnnosByIds(anno_ids):\n",
    "    result = []\n",
    "    for anno_id in anno_ids:  \n",
    "        result.append(videotag_anno_dic[anno_id])\n",
    "        \n",
    "    return result\n",
    "\n",
    "def saveBbox(anno_id, bbox):\n",
    "    for anno in videotag_anno:\n",
    "        if anno['id'] == anno_id:\n",
    "            anno['bbox'] = bbox\n",
    "            print('saved bbox', anno)\n",
    "            break\n",
    "\n",
    "extract_annotations = []\n",
    "\n",
    "\n",
    "###################################################################\n",
    "# 모든 이미지에 대하여 predict를 실시한다.\n",
    "###################################################################\n",
    "vt_img_total = len(videotag_imgs)\n",
    "for vt_img_current, vt_img in enumerate(videotag_imgs): \n",
    "    \n",
    "    if vt_img_current > 2:\n",
    "        break;\n",
    "    \n",
    "    print(str(vt_img_current)+'/'+str(vt_img_total))\n",
    "    img_id = vt_img['id']\n",
    "    \n",
    "    \n",
    "    ###################################################################\n",
    "    # videotag image에 등록되어 있느 annotation이 있는지 확인 후, 로드\n",
    "    ###################################################################\n",
    "    vt_annos = getAnnosByIds(videotag_img_anno_ids[img_id])\n",
    "    \n",
    "    if len(vt_annos) == 0:\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    ###################################################################\n",
    "    # videotag image이 로드\n",
    "    ###################################################################\n",
    "    img_path = os.path.join(IMAGE_DIR, vt_img['file_name']) \n",
    "    image = skimage.io.imread(img_path)\n",
    "    # If grayscale. Convert to RGB for consistency.\n",
    "    if image.ndim != 3:\n",
    "        image = skimage.color.gray2rgb(image)\n",
    "        \n",
    "    height, width = image.shape[:2]    \n",
    "        \n",
    "    \n",
    "    ###################################################################\n",
    "    # Run detection\n",
    "    ###################################################################\n",
    "    results = model.detect([image], verbose=0)\n",
    "\n",
    "    # Result\n",
    "    r = results[0]\n",
    "    \n",
    "    rois = r['rois'] # y1, x1, y2, x2\n",
    "    scores = r['scores']\n",
    "    masks = r['masks'] # (height, width, 검출된 데이타 갯수)\n",
    "    class_ids = r['class_ids']\n",
    "    \n",
    "    \n",
    "    # 확인용\n",
    "    confirm_coco_classes = [];\n",
    "    confirm_vt_classes = [];\n",
    "    confirm_vt_anno_points = []\n",
    "    for vt_anno in vt_annos:\n",
    "        point_x = int(width*vt_anno['x_pos'])\n",
    "        point_y = int(height*vt_anno['y_pos'])\n",
    "        confirm_vt_anno_points.append([point_y-5, point_x-5, point_y+5, point_x+5])\n",
    "        \n",
    "        vt_cate_id = vt_anno['category_id']\n",
    "        vt_cate_data = videotag_cate_dic[vt_cate_id]\n",
    "        confirm_vt_classes.append(vt_cate_data['name'])\n",
    "                \n",
    "    is_found = 0\n",
    "    \n",
    "    ###################################################################\n",
    "    # 추출된 Annotation을 VIDEOtag Annotation과 비교\n",
    "    ###################################################################\n",
    "    for index, score in enumerate(scores):\n",
    "#         if score < 0.9:\n",
    "#             continue\n",
    "        \n",
    "        image_id = image_id\n",
    "        category_id = class_ids[index]\n",
    "        category_name = class_names[category_id]\n",
    "        roi = rois[index]\n",
    "        bbox = [roi[1], roi[0], roi[3] - roi[1], roi[2] - roi[0]]\n",
    "        mask = masks[:, :, index]\n",
    "        \n",
    "        segm = maskUtils.encode(np.asfortranarray(mask))\n",
    "        rles = maskUtils.frPyObjects(segm, height, width)\n",
    "        rle = maskUtils.merge(rles)\n",
    "#         rle = maskUtils.decode(segmentation)\n",
    "        m = maskUtils.decode(rle)\n",
    "#         print('rle', rle)\n",
    "        print('m', m)\n",
    "        area = maskUtils.area(segmentation)\n",
    "        break;\n",
    "        \n",
    "        annotation = {}\n",
    "        annotation['bbox'] = bbox\n",
    "        annotation['category_id'] = category_id\n",
    "        annotation['id'] = ''\n",
    "        annotation['image_id'] = image_id\n",
    "        annotation['iscrowd'] = 0\n",
    "        '''\n",
    "        annotation['area'] = area\n",
    "        annotation['segmentation'] = segmentation\n",
    "        '''\n",
    "        # 확인용\n",
    "        confirm_coco_classes.append(category_name)\n",
    "        \n",
    "        ###################################################################\n",
    "        # coco model에서 검출된 annotation들이 videotag annotation(정답)들과 비교하여\n",
    "        # 일치할 경우가 있을 때, 해당 videotag annotation에 bbox정보를 추가한다.\n",
    "        ###################################################################\n",
    "        for vt_anno in vt_annos:\n",
    "            vt_anno_id = vt_anno['id']\n",
    "            vt_cate_id = vt_anno['category_id']\n",
    "            vt_cate_data = videotag_cate_dic[vt_cate_id]\n",
    "            vt_cate_name = vt_cate_data['name']\n",
    "            \n",
    "            point_x = int(width*vt_anno['x_pos'])\n",
    "            point_y = int(height*vt_anno['y_pos'])\n",
    "            \n",
    "            coco_cate_ids = videotag_coco_cate_map[vt_cate_id]['coco_ids']\n",
    "            if len(coco_cate_ids) == 0:\n",
    "                continue\n",
    "                \n",
    "            # NOTE: 포인트가 마스크 영역에 속하는 확인\n",
    "            if mask[point_y][point_x] == 0:\n",
    "                continue\n",
    "            \n",
    "#             vt_anno['bbox'] = bbox\n",
    "            saveBbox(vt_anno_id, bbox)\n",
    "            extract_annotations.append(annotation)\n",
    "            \n",
    "            for coco_cate_id in coco_cate_ids:\n",
    "                if coco_cate_id == category_id:\n",
    "                    print('찾았다', 'videotag : '+vt_cate_name, 'coco : '+category_name)\n",
    "#                     vt_anno['bbox'] = [1,1,1,1]\n",
    "                    is_found = 1\n",
    "                    break\n",
    "                    \n",
    "    print('결과값 비교 coco', confirm_coco_classes)\n",
    "    print('결과값 비교 videotag', confirm_vt_classes)\n",
    "    print('----------------------------------------------------------------------')\n",
    "    \n",
    "    if is_found:\n",
    "        visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'], confirm_videotag_anno_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('dataset/videotag/0101_0102/videotag_anno.json', 'w') as outfile:\n",
    "    json.dump(videotag_anno, outfile)\n",
    "\n",
    "with open('dataset/videotag/0101_0102/extract_annotations.json', 'w') as outfile:\n",
    "    json.dump(extract_annotations, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
