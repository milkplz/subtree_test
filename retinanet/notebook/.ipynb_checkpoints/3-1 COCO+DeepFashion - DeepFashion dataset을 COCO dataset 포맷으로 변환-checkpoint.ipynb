{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFashion dataset을 COCO dataset 포맷으로 변환합니다.\n",
    "\n",
    "### COCO - instances_val2017.json 요약 \n",
    "\n",
    "* categories : 90\n",
    "* image set : 120k (115k / 5k)\n",
    "* category index range : 1 ~ 90\n",
    "* image index : 1 ~\n",
    "```\n",
    "annotations : [{\n",
    "    area,         // Number - 영역 넓이(w*h)\n",
    "    bbox,         // [x,y,width,height], (Array(4))\n",
    "    category_id,  // int\n",
    "    id,           // int\n",
    "    image_id,     // int\n",
    "    iscrowd,      // 0 or 1 (get anns for given crowd label (False or True))\n",
    "    segmentation  // Array - mask 데이터 (RLE or [polygon])\n",
    "}, ...],\n",
    "categories : [{\n",
    "    id            // int\n",
    "    name          // String\n",
    "    supercategory // String\n",
    "}, ...],\n",
    "images : [{\n",
    "    id            // int\n",
    "    width         // int    \n",
    "    height        // int   \n",
    "    file_name     // String    \n",
    "    coco_url      // String\n",
    "    date_captured // String\n",
    "    flickr_url    // String\n",
    "    license       // int\n",
    "}, ...],\n",
    "info : {\n",
    "    contributor   // String\n",
    "    date_created  // datetime\n",
    "    description   // String\n",
    "    url           // String\n",
    "    version       // String\n",
    "    year          // int\n",
    "},\n",
    "licenses : [{\n",
    "    id            // int\n",
    "    name          // String\n",
    "    url           // String\n",
    "}, ...]\n",
    "```\n",
    "\n",
    "### DeepFashion - Category and Attribute Prediction Benchmark 요약\n",
    "의류에 집중되어 있음.\n",
    "* categories : 50\n",
    "* image set : 289k (259k / 30k)\n",
    "* category index range : 1 ~ 50\n",
    "* image index : 1 ~ (+500)\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "### DeepFashion dataset 포맷 변환\n",
    "* categories : 50\n",
    "* category index range : 100 ~ 150 (+100)\n",
    "* image set : 289k (259k / 30k)\n",
    "* image index : 500k ~ (+500k)\n",
    "#### 추가되는 정보\n",
    "* images\n",
    " * coco_url : local url 사용\n",
    " * date_captured : null\n",
    " * flickr_url : null\n",
    " * license : 0\n",
    "* info\n",
    " * contributor : deepfashion\n",
    " * date_created : now\n",
    " * description : 속성 값으로 대체\n",
    " * url : http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html\n",
    " * version : 1.0\n",
    " * year : 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/luke/Documents/dev/github/milkplz/keras-retinanet/notebook/dataset/deepfashion/annotations\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Root directory of the project\n",
    "DIR_ROOT = os.getcwd()\n",
    "DIR_DEEPFASHION = \"../dataset/deepfashion\"\n",
    "DIR_ROOT_DEEPFASHION = os.path.join(DIR_ROOT, DIR_DEEPFASHION)\n",
    "DIR_ROOT_DEEPFASHION_IMAGE = os.path.join(DIR_ROOT, DIR_DEEPFASHION, \"images\")\n",
    "DIR_ROOT_DEEPFASHION_ANNOTATIONS = os.path.join(DIR_ROOT, DIR_DEEPFASHION, \"annotations\")\n",
    "FILE_TRAIN_JSON = os.path.join(DIR_ROOT_DEEPFASHION_ANNOTATIONS, \"instances_train2017.json\")\n",
    "FILE_VAL_JSON = os.path.join(DIR_ROOT_DEEPFASHION_ANNOTATIONS, \"instances_val2017.json\")\n",
    "\n",
    "if not os.path.exists(DIR_ROOT_DEEPFASHION_IMAGE):\n",
    "    os.makedirs(DIR_ROOT_DEEPFASHION_IMAGE)\n",
    "    \n",
    "if not os.path.exists(DIR_ROOT_DEEPFASHION_ANNOTATIONS):\n",
    "    os.makedirs(DIR_ROOT_DEEPFASHION_ANNOTATIONS)\n",
    "    \n",
    "print(DIR_ROOT_DEEPFASHION_ANNOTATIONS)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "DEEPFASHION_CATEGORY_START_ID = 100\n",
    "DEEPFASHION_IMAGE_START_ID = 1000000000000\n",
    "DEEPFASHION_ANNO_START_ID = 1000000000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## categories object를 생성합니다.\n",
    "```\n",
    "categories : [{\n",
    "  id            // int\n",
    "  name          // String\n",
    "  supercategory // String\n",
    "}, ...]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categories sample [0] -  {'id': 101, 'name': 'Anorak', 'supercategory': 'upper-body'}\n"
     ]
    }
   ],
   "source": [
    "# path 설정\n",
    "path_list_category_cloth = os.path.join(DIR_DEEPFASHION, \"Anno\", \"list_category_cloth.txt\");\n",
    "\n",
    "# supercategory name 설정|\n",
    "supercategory_names = [\"upper-body\",\"lower-body\",\"full-body\"]\n",
    "\n",
    "# create category object\n",
    "categories = []\n",
    "with open(path_list_category_cloth) as file_list_category_cloth:\n",
    "    # 첫번째, 두번째 줄은 데이타의 정보를 나타내므로 skip 처리.\n",
    "    next(file_list_category_cloth)\n",
    "    next(file_list_category_cloth)\n",
    "    for index, line in enumerate(file_list_category_cloth):\n",
    "        super_category_index = int(line.strip()[-1:].strip().replace(' ', '_'))-1\n",
    "        category = {}\n",
    "        category['id'] = DEEPFASHION_CATEGORY_START_ID+index+1\n",
    "        category['name'] = line.strip()[:-1].strip().replace(' ', '_')\n",
    "        category['supercategory'] = supercategory_names[super_category_index]\n",
    "        categories.append(category);\n",
    "\n",
    "print('categories sample [0] - ', categories[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## annotations, images object를 생성합니다.\n",
    "이미지들은 deepfashion의 각 폴더별 경로에서 coco dataset과 같이 images폴더로 모두 이동시킵니다.\n",
    "\n",
    "```\n",
    "annotations : [{\n",
    "  area,         // Number - 영역 넓이(w*h)\n",
    "  bbox,         // [x,y,width,height], (Array(4))\n",
    "  category_id,  // int\n",
    "  id,           // int\n",
    "  image_id,     // int\n",
    "  iscrowd,      // 0 or 1 (get anns for given crowd label (False or True))\n",
    "  segmentation  // Array - mask 데이터 (RLE or [polygon])\n",
    "}, ...]\n",
    "\n",
    "images : [{\n",
    "  id            // int\n",
    "  width         // int    \n",
    "  height        // int   \n",
    "  file_name     // String    \n",
    "  coco_url      // String\n",
    "  date_captured // String\n",
    "  flickr_url    // String\n",
    "  license       // int\n",
    "}, ...],\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start parsing\n",
      "skip 2 line (data num, data type)\n",
      "end parsing\n",
      "sample - annotations[0] :  {'area': 31040, 'bbox': [72, 79, 160, 194], 'category_id': 103, 'id': 1000000000001, 'image_id': 1000000000001, 'iscrowd': 0, 'segmentation': []}\n",
      "sample - image[0] :  {'id': 1000000000001, 'width': 300, 'height': 300, 'file_name': '100000000001.jpg', 'coco_url': '../dataset/deepfashion/img/Sheer_Pleated-Front_Blouse/img_00000001.jpg', 'date_captured': '', 'flickr_url': '', 'license': 0}\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "\n",
    "# path 설정\n",
    "path_list_bbox = os.path.join(DIR_DEEPFASHION, \"Anno\", \"list_bbox.txt\");\n",
    "path_list_category_img = os.path.join(DIR_DEEPFASHION, \"Anno\", \"list_category_img.txt\"); \n",
    "\n",
    "# create annotations object\n",
    "annotations = []\n",
    "images = []\n",
    "\n",
    "print('start parsing')\n",
    "\n",
    "with open(path_list_bbox) as file_path_list_bbox:\n",
    "    with open(path_list_category_img) as file_path_list_category_img:\n",
    "        # 첫번째, 두번째 줄은 데이타의 정보를 나타내므로 skip 처리.\n",
    "        next(file_path_list_bbox)\n",
    "        next(file_path_list_bbox)\n",
    "        next(file_path_list_category_img)\n",
    "        next(file_path_list_category_img)        \n",
    "        print('skip 2 line (data num, data type)')\n",
    "        for index, (line_bbox, line_image) in enumerate(zip(file_path_list_bbox, file_path_list_category_img)):\n",
    "            # each rows\n",
    "            line_image = line_image.split()\n",
    "            line_bbox = line_bbox.split()\n",
    "            image_path = os.path.join(DIR_DEEPFASHION, line_image[0])\n",
    "            \n",
    "            image_format = line_image[0].split('/')[-1].split('.')[1]\n",
    "            image_name = str(index+100000000000+1).zfill(12)+'.'+image_format\n",
    "            new_image_path = os.path.join(DIR_ROOT_DEEPFASHION_IMAGE, image_name)\n",
    "            \n",
    "            # 이미지 파일 유무 확인\n",
    "            #if not os.path.exists(image_path):\n",
    "            #    continue\n",
    "            \n",
    "            # image경로를 통하여 같은 데이타인지 확인\n",
    "            if line_image[0] != line_bbox[0]:\n",
    "                print('error image path')\n",
    "                continue\n",
    "                \n",
    "            # get image size        \n",
    "            image_size = Image.open(image_path).size\n",
    "            if image_size[0]==0 or image_size[1]==0:\n",
    "                print('error image size')\n",
    "                continue\n",
    "            \n",
    "            # coco dataset과 동일한 local 경로로 파일 이동 또는 복사한다\n",
    "            # move file\n",
    "            # shutil.move(image_path, new_image_path)\n",
    "            # copy file\n",
    "            if not os.path.exists(new_image_path):\n",
    "                copyfile(image_path, new_image_path)\n",
    "                \n",
    "            \n",
    "            # set ids\n",
    "            annotation_id = DEEPFASHION_ANNO_START_ID+index+1\n",
    "            #category_id = int(line_image[1:][0])\n",
    "            category_id = DEEPFASHION_CATEGORY_START_ID+int(line_image[1:][0])\n",
    "            image_id = DEEPFASHION_IMAGE_START_ID+index+1\n",
    "            image_local_url = line_image[0]\n",
    "            \n",
    "            # bbox\n",
    "            bbox_x1 = int(line_bbox[1])\n",
    "            bbox_y1 = int(line_bbox[2])\n",
    "            bbox_x2 = int(line_bbox[3])\n",
    "            bbox_y2 = int(line_bbox[4])\n",
    "            bbox_width = int(bbox_x2-bbox_x1)\n",
    "            bbox_height = int(bbox_y2-bbox_y1)\n",
    "            \n",
    "            # set image object\n",
    "            image = {}\n",
    "            image['id'] = image_id\n",
    "            image['width'] = image_size[0]\n",
    "            image['height'] = image_size[1]\n",
    "            image['file_name'] = image_name\n",
    "            image['coco_url'] = image_path\n",
    "            image['date_captured'] = ''\n",
    "            image['flickr_url'] = ''\n",
    "            image['license'] = 0\n",
    "            \n",
    "            # set annotation\n",
    "            annotation = {}\n",
    "            annotation['area'] = bbox_width*bbox_height\n",
    "            annotation['bbox'] = [bbox_x1, bbox_y1, bbox_width, bbox_height]\n",
    "            annotation['category_id'] = category_id\n",
    "            annotation['id'] = annotation_id\n",
    "            annotation['image_id'] = image_id\n",
    "            annotation['iscrowd'] = 0\n",
    "            annotation['segmentation'] = []\n",
    "            \n",
    "            # add image, annotation\n",
    "            annotations.append(annotation);\n",
    "            images.append(image);\n",
    "            \n",
    "print('end parsing')\n",
    "\n",
    "print('sample - annotations[0] : ', annotations[0])\n",
    "print('sample - image[0] : ', images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random shuffle하여 train, validation dataset으로 분리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset -  260299\n",
      "val dataset -  28923\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# random shuffle\n",
    "zip_data = list(zip(annotations, images))\n",
    "random.shuffle(zip_data)\n",
    "annotations, images = zip(*zip_data)\n",
    "\n",
    "\n",
    "# create train, val dataset\n",
    "total = len(annotations)\n",
    "train_total = int(total*0.9) \n",
    "\n",
    "# train dataset\n",
    "train_annotations = annotations[:train_total]\n",
    "train_images = images[:train_total]\n",
    "\n",
    "# val dataset\n",
    "val_annotations = annotations[train_total:]\n",
    "val_images = images[train_total:]\n",
    "\n",
    "print('train dataset - ', len(train_annotations))\n",
    "print('val dataset - ', len(val_annotations))\n",
    "if train_annotations[0]['image_id'] != train_images[0]['id']:\n",
    "    print('suffle error')\n",
    "\n",
    "if val_annotations[0]['image_id'] != val_images[0]['id']:\n",
    "    print('suffle error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## categories, annotations, images -> json파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start - make json file\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/luke/Documents/dev/github/milkplz/keras-retinanet/notebook/dataset/deepfashion/annotations/instances_train2017.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f2fba3ddfc1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'categories'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFILE_TRAIN_JSON\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/luke/Documents/dev/github/milkplz/keras-retinanet/notebook/dataset/deepfashion/annotations/instances_train2017.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print('start - make json file')\n",
    "train_data = {}\n",
    "train_data['annotations'] = train_annotations\n",
    "train_data['categories'] = categories\n",
    "train_data['images'] = train_images\n",
    "with open(FILE_TRAIN_JSON, 'w') as outfile:\n",
    "    json.dump(train_data, outfile)\n",
    "    \n",
    "    \n",
    "val_data = {}\n",
    "val_data['annotations'] = val_annotations\n",
    "val_data['categories'] = categories\n",
    "val_data['images'] = val_images\n",
    "with open(FILE_VAL_JSON, 'w') as outfile:\n",
    "    json.dump(val_data, outfile)\n",
    "    \n",
    "print('end - make json file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'area': 24442, 'bbox': [42, 68, 121, 202], 'category_id': 119, 'id': 1000000087450, 'image_id': 1000000087450, 'iscrowd': 0, 'segmentation': []}\n",
      "{'id': 101, 'name': 'Anorak', 'supercategory': 'upper-body'}\n",
      "{'id': 1000000087450, 'width': 205, 'height': 300, 'file_name': '100000087450.jpg', 'coco_url': 'dataset/deepfashion/img/Abstract_Brushstroke_Pocket_Top/img_00000026.jpg', 'date_captured': '', 'flickr_url': '', 'license': 0}\n"
     ]
    }
   ],
   "source": [
    "print(train_data['annotations'][0])\n",
    "print(train_data['categories'][0])\n",
    "print(train_data['images'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
